filepath,content
c:\mygit\compuse\computer_use_demo\code_context_manager.py,"# code_context_manager.py

import os
import json
import re
import ast
import subprocess
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Set, Optional, List, Tuple

@dataclass
class CodeFile:
    name: str
    content: str
    version: int = 1
    last_modified: datetime = field(default_factory=datetime.now)
    dependencies: Set[str] = field(default_factory=set)
    description: Optional[str] = None

    def to_message(self) -> Dict[str, any]:
        """"""Convert CodeFile to a structured message for an LLM or any other consumer.""""""
        message_content = f""""""FILE CONTEXT:
**{self.name}** (v{self.version})
*Last Modified*: {self.last_modified.strftime('%Y-%m-%d %H:%M:%S')}
*Dependencies*: {', '.join(self.dependencies) if self.dependencies else 'None'}
*Description*: {self.description or 'No description provided.'}

**Content:**
```python
{self.content}
```""""""

        return {
            ""role"": ""user"",
            ""content"": [{
                ""type"": ""text"",
                ""text"": message_content
            }]
        }

def extract_code_blocks(response_text: str) -> List[Tuple[str, str]]:
    """"""
    Extracts code blocks from the response text.

    Returns a list of tuples containing the language and code.
    For example: [(""python"", ""def foo(): pass""), ...]
    """"""
    code_blocks = []
    # Regex to match code blocks with language specification
    pattern = re.compile(r""```(\w+)?\n([\s\S]*?)```"", re.MULTILINE)
    matches = pattern.findall(response_text)
    for lang, code in matches:
        language = lang.strip() if lang else ""plaintext""
        code_blocks.append((language, code.strip()))
    return code_blocks

def is_code_valid(code: str) -> bool:
    """"""
    Checks if the provided Python code is syntactically correct.
    """"""
    try:
        ast.parse(code)
        return True
    except SyntaxError as e:
        print(f""SyntaxError while parsing code: {e}"")
        return False

def replace_file(file_path: str, new_content: str) -> None:
    """"""
    Replaces the entire content of the specified file with new_content.
    """"""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    print(f""Replaced content of {file_path}"")

def insert_code_after_function(original_content: str, function_name: str, code_to_add: str) -> str:
    """"""
    Inserts code after the specified function in a Python file.
    """"""
    pattern = re.compile(rf""(def {re.escape(function_name)}\(.*?\):\s*[\s\S]*?)(?=def |\Z)"", re.MULTILINE)
    match = pattern.search(original_content)
    if match:
        insert_position = match.end()
        return original_content[:insert_position] + '\n\n' + code_to_add + original_content[insert_position:]
    else:
        # If function not found, append at the end
        return original_content + '\n\n' + code_to_add

def extract_single_code_block(code_block: str) -> Tuple[Optional[str], Optional[str]]:
    """"""
    Extracts a single code block's language and code.
    """"""
    match = re.match(r""```(\w+)?\n([\s\S]*?)```"", code_block, re.MULTILINE)
    if match:
        lang = match.group(1).strip() if match.group(1) else ""plaintext""
        code = match.group(2).strip()
        return lang, code
    return None, None

def commit_changes(message: str) -> None:
    """"""
    Commits changes to the git repository with the provided message.
    """"""
    try:
        subprocess.run([""git"", ""add"", "".""], check=True)
        subprocess.run([""git"", ""commit"", ""-m"", message], check=True)
        print(f""Changes committed: {message}"")
    except subprocess.CalledProcessError as e:
        print(f""Git commit failed: {e}"")

def run_tests() -> bool:
    """"""
    Runs the test suite and returns True if all tests pass.
    """"""
    try:
        subprocess.run([""pytest""], check=True)
        print(""All tests passed."")
        return True
    except subprocess.CalledProcessError:
        print(""Some tests failed."")
        return False

def revert_last_commit() -> None:
    """"""
    Reverts the last git commit.
    """"""
    try:
        subprocess.run([""git"", ""reset"", ""--hard"", ""HEAD~1""], check=True)
        print(""Reverted the last commit."")
    except subprocess.CalledProcessError as e:
        print(f""Failed to revert commit: {e}"")

class CodeContextManager:
    def __init__(self, persistence_file: Optional[str] = None):
        self.files: Dict[str, CodeFile] = {}
        self.persistence_file = persistence_file
        if self.persistence_file:
            self.load_from_disk()

    def update_file(self, 
                   name: str, 
                   content: str, 
                   dependencies: Optional[Set[str]] = None, 
                   description: Optional[str] = None) -> None:
        """"""Add or update a file in the context.""""""
        if name in self.files:
            existing_file = self.files[name]
            existing_file.version += 1
            existing_file.content = content
            existing_file.last_modified = datetime.now()
            if dependencies is not None:
                existing_file.dependencies = dependencies
            if description is not None:
                existing_file.description = description
            print(f""Updated file: {name} to version {existing_file.version}"")
        else:
            self.files[name] = CodeFile(
                name=name,
                content=content,
                dependencies=dependencies or set(),
                description=description
            )
            print(f""Added new file: {name}"")

        if self.persistence_file:
            self.save_to_disk()

    def get_context_messages(self) -> List[Dict[str, any]]:
        """"""Get all file contexts as messages.""""""
        return [file.to_message() for file in self.files.values()]

    def save_to_disk(self) -> None:
        """"""Persist the current code context to disk.""""""
        data = {
            name: {
                ""name"": file.name,
                ""content"": file.content,
                ""version"": file.version,
                ""last_modified"": file.last_modified.isoformat(),
                ""dependencies"": list(file.dependencies),
                ""description"": file.description
            } for name, file in self.files.items()
        }
        with open(self.persistence_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4)
        print(f""Saved code context to {self.persistence_file}"")

    def load_from_disk(self) -> None:
        """"""Load the code context from disk.""""""
        if not os.path.exists(self.persistence_file):
            print(f""Persistence file {self.persistence_file} does not exist. Starting fresh."")
            return

        with open(self.persistence_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            for name, file_data in data.items():
                self.files[name] = CodeFile(
                    name=file_data[""name""],
                    content=file_data[""content""],
                    version=file_data[""version""],
                    last_modified=datetime.fromisoformat(file_data[""last_modified""]),
                    dependencies=set(file_data[""dependencies""]),
                    description=file_data.get(""description"")
                )
        print(f""Loaded code context from {self.persistence_file}"")

    def remove_file(self, name: str) -> None:
        """"""Remove a file from the context.""""""
        if name in self.files:
            del self.files[name]
            print(f""Removed file: {name}"")
            if self.persistence_file:
                self.save_to_disk()
        else:
            print(f""Tried to remove non-existent file: {name}"")

    def apply_llm_response(self, response_text: str) -> None:
        """"""
        Parses the LLM response, extracts code blocks, and updates the relevant files.
        Assumes the LLM follows a specific format to indicate target files and update types.

        Example LLM response format:

        ### Update file1.py
        ```python
        def greet(name, greeting=""Hello""):
            return f""{greeting}, {name}!""
        ```

        ### Add to file2.py
        ```python
        def new_function():
            pass
        ```
        """"""
        # Split the response into sections based on filenames
        sections = re.split(r'###\s+(?:Update|Add)\s+(\S+)', response_text)
        
        # The split will result in a list where filenames are captured in group 1
        # Process in pairs: [text, filename, action, text, filename, action, ...]
        it = iter(sections)
        for section in it:
            if not section.strip():
                continue
            # Get filename
            filename = section.strip()
            # Get action (assume that 'Update' or 'Add' was matched before the filename)
            # Since regex does not capture action, infer it
            action_match = re.search(r'###\s+(Update|Add)\s+', section)
            action = ""full_replace"" if ""Update"" in section else ""add_code""
            
            # Get the next item which should be the code block
            try:
                code_block = next(it).strip()
                lang, code = extract_single_code_block(code_block)
                if not code:
                    print(f""No code found in section for {filename}. Skipping."")
                    continue
                if not is_code_valid(code):
                    print(f""Invalid code for {filename}. Skipping."")
                    continue

                if action == ""full_replace"":
                    self.replace_file_content(filename, code)
                    commit_changes(f""Replaced content of {filename}"")
                elif action == ""add_code"":
                    # Optionally, specify function or location
                    # For simplicity, appending to the end
                    self.add_code_to_file(filename, code)
                    commit_changes(f""Added code to {filename}"")
                
                # Run tests after each change
                if run_tests():
                    print(f""Changes to {filename} passed tests."")
                else:
                    print(f""Tests failed after changes to {filename}. Reverting."")
                    revert_last_commit()
            except StopIteration:
                break

    def replace_file_content(self, filename: str, new_content: str) -> None:
        """"""
        Replaces the entire content of the specified file.
        """"""
        file_path = os.path.join('code_files', filename)
        if os.path.exists(file_path):
            replace_file(file_path, new_content)
            self.update_file(
                name=filename,
                content=new_content,
                dependencies=self.extract_dependencies(new_content),
                description=self.files[filename].description  # Keep existing description
            )
        else:
            print(f""File {filename} does not exist. Creating a new one."")
            replace_file(file_path, new_content)
            self.update_file(
                name=filename,
                content=new_content,
                dependencies=self.extract_dependencies(new_content),
                description=""Automatically created file.""
            )

    def add_code_to_file(self, filename: str, code_to_add: str, function_name: Optional[str] = None) -> None:
        """"""
        Adds new code to an existing file. Optionally, specify the function name for better placement.
        """"""
        file_path = os.path.join('code_files', filename)
        if not os.path.exists(file_path):
            print(f""File {filename} does not exist. Creating a new one."")
            replace_file(file_path, code_to_add)
            self.update_file(
                name=filename,
                content=code_to_add,
                dependencies=self.extract_dependencies(code_to_add),
                description=""Automatically created file.""
            )
            return

        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        if function_name:
            # Insert code after the specified function
            updated_content = insert_code_after_function(original_content, function_name, code_to_add)
        else:
            # Append code at the end
            updated_content = original_content + '\n\n' + code_to_add

        replace_file(file_path, updated_content)

        self.update_file(
            name=filename,
            content=updated_content,
            dependencies=self.extract_dependencies(updated_content),
            description=self.files[filename].description
        )
        print(f""Added code to {filename}"")

    def extract_dependencies(self, content: str) -> Set[str]:
        """"""
        Extracts dependencies from the given Python file content.
        """"""
        dependencies = set()
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        dependencies.add(alias.name.split('.')[0] + '.py')
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        dependencies.add(node.module.split('.')[0] + '.py')
        except SyntaxError:
            pass
        # Filter dependencies to include only local files
        return {dep for dep in dependencies if dep in self.files}
"
c:\mygit\compuse\computer_use_demo\computer.py,"import asyncio
import base64
import os
import shlex
import shutil
from enum import StrEnum
from pathlib import Path
from typing import Literal, TypedDict
from uuid import uuid4

from anthropic.types.beta import BetaToolComputerUse20241022Param

from tools.base import BaseAnthropicTool, ToolError, ToolResult
from tools.run import run

OUTPUT_DIR = ""/tmp/outputs""

TYPING_DELAY_MS = 12
TYPING_GROUP_SIZE = 50

Action = Literal[
    ""key"",
    ""type"",
    ""mouse_move"",
    ""left_click"",
    ""left_click_drag"",
    ""right_click"",
    ""middle_click"",
    ""double_click"",
    ""screenshot"",
    ""cursor_position"",
]


class Resolution(TypedDict):
    width: int
    height: int


# sizes above XGA/WXGA are not recommended (see README.md)
# scale down to one of these targets if ComputerTool._scaling_enabled is set
MAX_SCALING_TARGETS: dict[str, Resolution] = {
    ""XGA"": Resolution(width=1024, height=768),  # 4:3
    ""WXGA"": Resolution(width=1280, height=800),  # 16:10
    ""FWXGA"": Resolution(width=1366, height=768),  # ~16:9
}


class ScalingSource(StrEnum):
    COMPUTER = ""computer""
    API = ""api""


class ComputerToolOptions(TypedDict):
    display_height_px: int
    display_width_px: int
    display_number: int | None


def chunks(s: str, chunk_size: int) -> list[str]:
    return [s[i : i + chunk_size] for i in range(0, len(s), chunk_size)]


class ComputerTool(BaseAnthropicTool):
    """"""
    A tool that allows the agent to interact with the screen, keyboard, and mouse of the current computer.
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    name: Literal[""computer""] = ""computer""
    api_type: Literal[""computer_20241022""] = ""computer_20241022""
    width: int
    height: int
    display_num: int | None

    _screenshot_delay = 2.0
    _scaling_enabled = True

    @property
    def options(self) -> ComputerToolOptions:
        width, height = self.scale_coordinates(
            ScalingSource.COMPUTER, self.width, self.height
        )
        return {
            ""display_width_px"": width,
            ""display_height_px"": height,
            ""display_number"": self.display_num,
        }

    def to_params(self) -> BetaToolComputerUse20241022Param:
        return {""name"": self.name, ""type"": self.api_type, **self.options}

    def __init__(self):
        super().__init__()

        self.width = int(os.getenv(""WIDTH"") or 0)
        self.height = int(os.getenv(""HEIGHT"") or 0)
        assert self.width and self.height, ""WIDTH, HEIGHT must be set""
        if (display_num := os.getenv(""DISPLAY_NUM"")) is not None:
            self.display_num = int(display_num)
            self._display_prefix = f""DISPLAY=:{self.display_num} ""
        else:
            self.display_num = None
            self._display_prefix = """"

        self.xdotool = f""{self._display_prefix}xdotool""

    async def __call__(
        self,
        *,
        action: Action,
        text: str | None = None,
        coordinate: tuple[int, int] | None = None,
        **kwargs,
    ):
        if action in (""mouse_move"", ""left_click_drag""):
            if coordinate is None:
                raise ToolError(f""coordinate is required for {action}"")
            if text is not None:
                raise ToolError(f""text is not accepted for {action}"")
            if not isinstance(coordinate, list) or len(coordinate) != 2:
                raise ToolError(f""{coordinate} must be a tuple of length 2"")
            if not all(isinstance(i, int) and i >= 0 for i in coordinate):
                raise ToolError(f""{coordinate} must be a tuple of non-negative ints"")

            x, y = self.scale_coordinates(
                ScalingSource.API, coordinate[0], coordinate[1]
            )

            if action == ""mouse_move"":
                return await self.shell(f""{self.xdotool} mousemove --sync {x} {y}"")
            elif action == ""left_click_drag"":
                return await self.shell(
                    f""{self.xdotool} mousedown 1 mousemove --sync {x} {y} mouseup 1""
                )

        if action in (""key"", ""type""):
            if text is None:
                raise ToolError(f""text is required for {action}"")
            if coordinate is not None:
                raise ToolError(f""coordinate is not accepted for {action}"")
            if not isinstance(text, str):
                raise ToolError(output=f""{text} must be a string"")

            if action == ""key"":
                return await self.shell(f""{self.xdotool} key -- {text}"")
            elif action == ""type"":
                results: list[ToolResult] = []
                for chunk in chunks(text, TYPING_GROUP_SIZE):
                    cmd = f""{self.xdotool} type --delay {TYPING_DELAY_MS} -- {shlex.quote(chunk)}""
                    results.append(await self.shell(cmd, take_screenshot=False))
                screenshot_base64 = (await self.screenshot()).base64_image
                return ToolResult(
                    output="""".join(result.output or """" for result in results),
                    error="""".join(result.error or """" for result in results),
                    base64_image=screenshot_base64,
                )

        if action in (
            ""left_click"",
            ""right_click"",
            ""double_click"",
            ""middle_click"",
            ""screenshot"",
            ""cursor_position"",
        ):
            if text is not None:
                raise ToolError(f""text is not accepted for {action}"")
            if coordinate is not None:
                raise ToolError(f""coordinate is not accepted for {action}"")

            if action == ""screenshot"":
                return await self.screenshot()
            elif action == ""cursor_position"":
                result = await self.shell(
                    f""{self.xdotool} getmouselocation --shell"",
                    take_screenshot=False,
                )
                output = result.output or """"
                x, y = self.scale_coordinates(
                    ScalingSource.COMPUTER,
                    int(output.split(""X="")[1].split(""\n"")[0]),
                    int(output.split(""Y="")[1].split(""\n"")[0]),
                )
                return result.replace(output=f""X={x},Y={y}"")
            else:
                click_arg = {
                    ""left_click"": ""1"",
                    ""right_click"": ""3"",
                    ""middle_click"": ""2"",
                    ""double_click"": ""--repeat 2 --delay 500 1"",
                }[action]
                return await self.shell(f""{self.xdotool} click {click_arg}"")

        raise ToolError(f""Invalid action: {action}"")

    async def screenshot(self):
        """"""Take a screenshot of the current screen and return the base64 encoded image.""""""
        output_dir = Path(OUTPUT_DIR)
        output_dir.mkdir(parents=True, exist_ok=True)
        path = output_dir / f""screenshot_{uuid4().hex}.png""

        # Try gnome-screenshot first
        if shutil.which(""gnome-screenshot""):
            screenshot_cmd = f""{self._display_prefix}gnome-screenshot -f {path} -p""
        else:
            # Fall back to scrot if gnome-screenshot isn't available
            screenshot_cmd = f""{self._display_prefix}scrot -p {path}""

        result = await self.shell(screenshot_cmd, take_screenshot=False)
        if self._scaling_enabled:
            x, y = self.scale_coordinates(
                ScalingSource.COMPUTER, self.width, self.height
            )
            await self.shell(
                f""convert {path} -resize {x}x{y}! {path}"", take_screenshot=False
            )

        if path.exists():
            return result.replace(
                base64_image=base64.b64encode(path.read_bytes()).decode()
            )
        raise ToolError(f""Failed to take screenshot: {result.error}"")

    async def shell(self, command: str, take_screenshot=True) -> ToolResult:
        """"""Run a shell command and return the output, error, and optionally a screenshot.""""""
        _, stdout, stderr = await run(command)
        base64_image = None

        if take_screenshot:
            # delay to let things settle before taking a screenshot
            await asyncio.sleep(self._screenshot_delay)
            base64_image = (await self.screenshot()).base64_image

        return ToolResult(output=stdout, error=stderr, base64_image=base64_image)

    def scale_coordinates(self, source: ScalingSource, x: int, y: int):
        """"""Scale coordinates to a target maximum resolution.""""""
        if not self._scaling_enabled:
            return x, y
        ratio = self.width / self.height
        target_dimension = None
        for dimension in MAX_SCALING_TARGETS.values():
            # allow some error in the aspect ratio - not ratios are exactly 16:9
            if abs(dimension[""width""] / dimension[""height""] - ratio) < 0.02:
                if dimension[""width""] < self.width:
                    target_dimension = dimension
                break
        if target_dimension is None:
            return x, y
        # should be less than 1
        x_scaling_factor = target_dimension[""width""] / self.width
        y_scaling_factor = target_dimension[""height""] / self.height
        if source == ScalingSource.API:
            if x > self.width or y > self.height:
                raise ToolError(f""Coordinates {x}, {y} are out of bounds"")
            # scale up
            return round(x / x_scaling_factor), round(y / y_scaling_factor)
        # scale down
        return round(x * x_scaling_factor), round(y * y_scaling_factor)
"
c:\mygit\compuse\computer_use_demo\cputest.py,"""""""
Cross-platform agentic sampling loop that calls the Anthropic API and local implementation of anthropic-defined computer use tools.
""""""

import asyncio
import os
import platform
from datetime import datetime
from enum import StrEnum
from pathlib import Path
from typing import Any, Callable, List, Optional, TypedDict, cast

from anthropic import Anthropic, AnthropicBedrock, AnthropicVertex, APIResponse
from anthropic.types import ToolResultBlockParam
from anthropic.types.beta import (
    BetaContentBlock,
    BetaContentBlockParam,
    BetaImageBlockParam,
    BetaMessage,
    BetaMessageParam,
    BetaTextBlockParam,
    BetaToolResultBlockParam,
)

from tools import BashTool, ComputerTool, EditTool, ToolCollection, ToolResult

# Constants
BETA_FLAG = ""computer-use-2024-10-22""

# Set up platform-specific paths and directories
if platform.system() == 'Windows':
    OUTPUT_DIR = Path(os.getenv('APPDATA', '.')) / 'computer_tool' / 'outputs'
    DOWNLOAD_CMD = ""Invoke-WebRequest -Uri {url} -OutFile {output}""
    APP_LAUNCH_CMD = ""Start-Process""
else:
    OUTPUT_DIR = Path.home() / '.computer_tool' / 'outputs'
    DOWNLOAD_CMD = ""curl -L {url} -o {output}""
    APP_LAUNCH_CMD = ""xdg-open""  # Linux
    if platform.system() == 'Darwin':  # macOS
        APP_LAUNCH_CMD = ""open""

# Ensure output directory exists
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

TYPING_DELAY_MS = 8
TYPING_GROUP_SIZE = 50

# Scaling Targets
class Resolution(TypedDict):
    width: int
    height: int

MAX_SCALING_TARGETS: dict[str, Resolution] = {
    ""XGA"": Resolution(width=1024, height=768),       # 4:3
    ""WXGA"": Resolution(width=1280, height=800),      # 16:10
    ""FWXGA"": Resolution(width=1366, height=768),     # ~16:9
}

# API Providers
class APIProvider(StrEnum):
    ANTHROPIC = ""anthropic""
    BEDROCK = ""bedrock""
    VERTEX = ""vertex""

PROVIDER_TO_DEFAULT_MODEL_NAME: dict[APIProvider, str] = {
    APIProvider.ANTHROPIC: ""claude-3-5-sonnet-20241022"",
    APIProvider.BEDROCK: ""anthropic.claude-3-5-sonnet-20241022-v2:0"",
    APIProvider.VERTEX: ""claude-3-5-sonnet-v2@20241022"",
}

def get_platform_specific_system_prompt() -> str:
    """"""Generate a platform-specific system prompt.""""""
    system = platform.system()
    arch = platform.machine()
    
    if system == ""Windows"":
        return f""""""<SYSTEM_CAPABILITY>
* You are utilizing a Windows machine using {arch} architecture with internet access.
* You can install Windows applications using PowerShell. Use Invoke-WebRequest for downloading files.
* To open applications, use pyautogui to press the Windows key and type the application name followed by enter.
* If GUI app launching fails, you can use PowerShell's Start-Process command as a fallback.
* When using PowerShell with commands that may produce large output, redirect to a temporary file and use Select-String for filtering.
* The current date is {datetime.today()}.
</SYSTEM_CAPABILITY>""""""
    elif system == ""Darwin"":
        return f""""""<SYSTEM_CAPABILITY>
* You are utilizing a macOS machine using {arch} architecture with internet access.
* You can install applications using brew or curl for downloading files.
* To open applications, use pyautogui to press command+space and type the application name.
* The terminal can launch GUI apps using the 'open' command.
* When dealing with large command output, use grep or redirect to temporary files.
* The current date is {datetime.today()}.
</SYSTEM_CAPABILITY>""""""
    else:  # Linux
        return f""""""<SYSTEM_CAPABILITY>
* You are utilizing a Linux machine using {arch} architecture with internet access.
* You can install applications using the system package manager or curl for downloading files.
* To open applications, use pyautogui to press the appropriate shortcut for your desktop environment.
* GUI applications can be launched using xdg-open.
* When dealing with large command output, use grep or redirect to temporary files.
* The current date is {datetime.today()}.
</SYSTEM_CAPABILITY>""""""

# Common instructions for all platforms
COMMON_INSTRUCTIONS = """"""
<IMPORTANT>
* When using a web browser, if a startup wizard appears, IGNORE IT. Click directly on the address bar and enter the URL.
* For PDF documents, rather than navigating through screenshots, download the PDF and convert it to text for direct reading.
* When viewing pages, consider zooming out for better visibility or ensure you scroll to see all content.
* Computer function calls take time to execute and return. Where possible, chain multiple calls together.
</IMPORTANT>""""""

# System Prompt combining platform-specific and common instructions
SYSTEM_PROMPT = get_platform_specific_system_prompt() + COMMON_INSTRUCTIONS

# Helper Functions
def chunks(s: str, chunk_size: int) -> List[str]:
    """"""Split a string into chunks of specified size.""""""
    return [s[i : i + chunk_size] for i in range(0, len(s), chunk_size)]

def _maybe_filter_to_n_most_recent_images(
    messages: List[BetaMessageParam],
    images_to_keep: int,
    min_removal_threshold: int = 10,
):
    """"""Filters out older images from the messages to keep memory usage in check.""""""
    if images_to_keep is None:
        return

    tool_result_blocks = cast(
        List[ToolResultBlockParam],
        [
            item
            for message in messages
            for item in (
                message[""content""] if isinstance(message[""content""], list) else []
            )
            if isinstance(item, dict) and item.get(""type"") == ""tool_result""
        ],
    )

    total_images = sum(
        1
        for tool_result in tool_result_blocks
        for content in tool_result.get(""content"", [])
        if isinstance(content, dict) and content.get(""type"") == ""image""
    )

    images_to_remove = total_images - images_to_keep
    if images_to_remove <= 0:
        return

    images_to_remove -= images_to_remove % min_removal_threshold

    for tool_result in tool_result_blocks:
        if isinstance(tool_result.get(""content""), list):
            new_content = []
            for content in tool_result.get(""content"", []):
                if isinstance(content, dict) and content.get(""type"") == ""image"":
                    if images_to_remove > 0:
                        images_to_remove -= 1
                        continue
                new_content.append(content)
            tool_result[""content""] = new_content
            if images_to_remove <= 0:
                break

def _make_api_tool_result(
    result: ToolResult, tool_use_id: str
) -> BetaToolResultBlockParam:
    """"""Convert an agent ToolResult to an API ToolResultBlockParam.""""""
    tool_result_content: List[
        BetaTextBlockParam | BetaImageBlockParam
    ] = []
    is_error = False
    if result.error:
        is_error = True
        tool_result_content = _maybe_prepend_system_tool_result(result, result.error)
    else:
        if result.output:
            tool_result_content.append(
                {
                    ""type"": ""text"",
                    ""text"": _maybe_prepend_system_tool_result(result, result.output),
                }
            )
        if result.base64_image:
            tool_result_content.append(
                {
                    ""type"": ""image"",
                    ""source"": {
                        ""type"": ""base64"",
                        ""media_type"": ""image/png"",
                        ""data"": result.base64_image,
                    },
                }
            )
    return {
        ""type"": ""tool_result"",
        ""content"": tool_result_content,
        ""tool_use_id"": tool_use_id,
        ""is_error"": is_error,
    }

def _maybe_prepend_system_tool_result(result: ToolResult, result_text: str) -> str:
    """"""Prepend system information to tool result if available.""""""
    if result.system:
        result_text = f""<system>{result.system}</system>\n{result_text}""
    return result_text

# Sampling Loop
async def sampling_loop(
    *,
    model: str,
    provider: APIProvider,
    system_prompt_suffix: str,
    messages: List[BetaMessageParam],
    output_callback: Callable[[BetaContentBlock], None],
    tool_output_callback: Callable[[ToolResult, str], None],
    api_response_callback: Callable[[APIResponse[BetaMessage]], None],
    api_key: str,
    only_n_most_recent_images: Optional[int] = None,
    max_tokens: int = 4096,
) -> List[BetaMessageParam]:
    """"""Sampling loop for the assistant/tool interaction of computer use.""""""
    tool_collection = ToolCollection(
        ComputerTool(),
        BashTool(),
        EditTool(),
    )
    system = (
        f""{SYSTEM_PROMPT}{' ' + system_prompt_suffix if system_prompt_suffix else ''}""
    )

    while True:
        if only_n_most_recent_images:
            _maybe_filter_to_n_most_recent_images(messages, only_n_most_recent_images)

        # Initialize appropriate client based on provider
        if provider == APIProvider.ANTHROPIC:
            client = Anthropic(api_key=api_key)
        elif provider == APIProvider.VERTEX:
            client = AnthropicVertex()
        elif provider == APIProvider.BEDROCK:
            client = AnthropicBedrock()
        else:
            raise ValueError(f""Unsupported API provider: {provider}"")

        # Call the API
        response = client.beta.messages.create(
            max_tokens=max_tokens,
            messages=messages,
            model=model,
            system=system,
            tools=tool_collection.to_params(),
            betas=[BETA_FLAG],
        )

        api_response_callback(cast(APIResponse[BetaMessage], response))

        messages.append(
            {
                ""role"": ""assistant"",
                ""content"": cast(List[BetaContentBlockParam], response.content),
            }
        )

        tool_result_content: List[BetaToolResultBlockParam] = []
        for content_block in cast(List[BetaContentBlock], response.content):
            output_callback(content_block)
            if content_block.type == ""tool_use"":
                result = await tool_collection.run(
                    name=content_block.name,
                    tool_input=cast(dict[str, Any], content_block.input),
                )
                tool_result_content.append(
                    _make_api_tool_result(result, content_block.id)
                )
                tool_output_callback(result, content_block.id)

        if tool_result_content:
            messages.append({""content"": tool_result_content, ""role"": ""user""})
        else:
            return messages

# Main Function
async def run_sampling_loop() -> List[BetaMessageParam]:
    """"""Main function to run the sampling loop.""""""
    api_key = os.getenv(""ANTHROPIC_API_KEY"")
    if not api_key:
        raise ValueError(""API key not found. Please set the ANTHROPIC_API_KEY environment variable."")

    messages = await sampling_loop(
        model=PROVIDER_TO_DEFAULT_MODEL_NAME[APIProvider.ANTHROPIC],
        provider=APIProvider.ANTHROPIC,
        system_prompt_suffix="""",
        messages=[{
            ""role"": ""user"",
            ""content"": ""Save a documentation of Anthropic's cpu_use_tool to my desktop in markdown format.""
        }],
        output_callback=lambda x: print(x),
        tool_output_callback=lambda x, y: print(f""Tool Output: {x}, ID: {y}""),
        api_response_callback=lambda x: print(f""API Response: {x}""),
        api_key=api_key,
    )
    return messages

def main():
    """"""Entry point for the application.""""""
    async def main_async():
        messages = await run_sampling_loop()
        print(""Final Messages:"")
        for msg in messages:
            print(msg)

    if asyncio.get_event_loop().is_running():
        asyncio.create_task(main_async())
    else:
        asyncio.run(main_async())

if __name__ == ""__main__"":
    main()

"
c:\mygit\compuse\computer_use_demo\edit_tool.py,"edit_tool.py

import os
import re
from pathlib import Path
from collections import defaultdict
from typing import Literal, List, Dict, Any, Optional
import logging
from rich import print as rr

# Importing BaseAnthropicTool and ToolResult from your base module
from .base import BaseAnthropicTool, ToolResult, ToolError

# Configure logging for user feedback and debugging
logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')

# Define the allowed commands
Command = Literal[
    ""view"",
    ""create"",
    ""str_replace"",
    ""insert"",
    ""undo_edit"",
]

SNIPPET_LINES: int = 4


class EditTool(BaseAnthropicTool):
    """"""
    A cross-platform filesystem editor tool that allows the agent to view, create, and edit files.
    """"""

    description = """"""
    A cross-platform filesystem editor tool that allows the agent to view, create, and edit files.
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    api_type: Literal[""text_editor_20241022""] = ""text_editor_20241022""
    name: Literal[""str_replace_editor""] = ""str_replace_editor""

    _file_history: Dict[Path, List[str]]

    def __init__(self):
        self._file_history = defaultdict(list)
        super().__init__()

    def to_params(self) -> Dict[str, Any]:
        return {
            ""name"": self.name,
            ""type"": self.api_type,
        }

    async def __call__(
        self,
        *,
        command: Command,
        path: str,
        file_text: Optional[str] = None,
        view_range: Optional[List[int]] = None,
        old_str: Optional[str] = None,
        new_str: Optional[str] = None,
        insert_line: Optional[int] = None,
        **kwargs,
    ) -> ToolResult:
        """"""
        Executes the specified command on the given file path with optional parameters.
        """"""
        logging.info(f""Received command '{command}' for path '{path}' with params: {kwargs}"")
        _path = Path(path).resolve()  # Resolve to handle both Windows and Unix paths
        logging.info(f""Resolved path: {_path}"")

        try:
            if command == ""view"":
                logging.info(""Executing 'view' command."")
                return await self.view(_path, view_range)
            elif command == ""create"":
                if not file_text:
                    raise ToolError(""Parameter `file_text` is required for command: create"")
                self.write_file(_path, file_text)
                logging.info(""File created successfully."")
                self._file_history[_path].append(file_text)
                return ToolResult(output=f""File created successfully at: {_path}"")
            elif command == ""str_replace"":
                if not old_str:
                    raise ToolError(""Parameter `old_str` is required for command: str_replace"")
                return self.str_replace(_path, old_str, new_str)
            elif command == ""insert"":
                if insert_line is None:
                    raise ToolError(""Parameter `insert_line` is required for command: insert"")
                if not new_str:
                    raise ToolError(""Parameter `new_str` is required for command: insert"")
                return self.insert(_path, insert_line, new_str)
            elif command == ""undo_edit"":
                return self.undo_edit(_path)
            else:
                raise ToolError(
                    f'Unrecognized command {command}. The allowed commands for the {self.name} tool are: {"", "".join(get_args(Command))}'
                )
        except ToolError as te:
            logging.error(f""ToolError: {te}"")
            return ToolResult(output=None, error=str(te), base64_image=None)
        except Exception as e:
            logging.error(f""Unexpected error: {e}"")
            return ToolResult(output=None, error=str(e), base64_image=None)

    def normalize_path(self, path: Optional[str]) -> Path:
        """"""
        Normalize a file path to ensure it starts with 'C:/repo/'.
        """"""
        if not path:
            raise ValueError('Path cannot be empty')

        # Convert to string in case we receive a Path object
        normalized_path = str(path)

        # Convert all backslashes to forward slashes
        normalized_path = normalized_path.replace('\\', '/')

        # Remove any leading/trailing whitespace
        normalized_path = normalized_path.strip()

        # Remove multiple consecutive forward slashes
        normalized_path = re.sub(r'/+', '/', normalized_path)

        # Remove 'C:' or 'c:' if it exists at the start
        normalized_path = re.sub(r'^[cC]:', '', normalized_path)

        # Remove '/repo/' if it exists at the start
        normalized_path = re.sub(r'^/repo/', '', normalized_path)

        # Remove leading slash if it exists
        normalized_path = re.sub(r'^/', '', normalized_path)

        # Combine with base path
        return Path(f'C:/repo/{normalized_path}')

    def validate_path(self, command: str, path: Path):
        """"""
        Check that the path/command combination is valid in a cross-platform manner.
        """"""
        path = self.normalize_path(str(path))
        try:
            # This handles both Windows and Unix paths correctly
            path = path.resolve()
        except Exception as e:
            raise ToolError(f""Invalid path format: {path}. Error: {str(e)}"")

        # Check if it's an absolute path
        if not path.is_absolute():
            suggested_path = Path.cwd() / path
            raise ToolError(
                f""The path {path} is not an absolute path. Maybe you meant {suggested_path}?""
            )

        # Check if path exists
        if not path.exists() and command != ""create"":
            raise ToolError(
                f""The path {path} does not exist. Please provide a valid path.""
            )
        if path.exists() and command == ""create"":
            raise ToolError(
                f""File already exists at: {path}. Cannot overwrite files using command `create`.""
            )

        # Check if the path points to a directory
        if path.is_dir():
            if command != ""view"":
                raise ToolError(
                    f""The path {path} is a directory and only the `view` command can be used on directories""
                )

    async def view(self, path: Path, view_range: Optional[List[int]] = None) -> ToolResult:
        """"""Implement the view command using cross-platform methods.""""""
        logging.info(f""Executing 'view' on path: {path} with view_range: {view_range}"")
        path = self.normalize_path(str(path))

        if path.is_dir():
            if view_range:
                raise ToolError(
                    ""The `view_range` parameter is not allowed when `path` points to a directory.""
                )

            try:
                # Cross-platform directory listing using pathlib
                files = []
                for level in range(3):  # 0-2 levels deep
                    if level == 0:
                        pattern = ""*""
                    else:
                        pattern = os.path.join(*[""*""] * (level + 1))

                    for item in path.glob(pattern):
                        # Skip hidden files and directories
                        if not any(part.startswith('.') for part in item.parts):
                            files.append(str(item.resolve()))  # Ensure absolute paths

                stdout = ""\n"".join(sorted(files))
                stdout = f""Here's the files and directories up to 2 levels deep in {path}, excluding hidden items:\n{stdout}\n""
                logging.info(f""'view' command successful on directory: {path}"")
                return ToolResult(output=stdout, error=None, base64_image=None)
            except Exception as e:
                logging.error(f""Error executing 'view' on directory: {e}"")
                return ToolResult(output="""", error=str(e), base64_image=None)

        # If it's a file, read its content
        try:
            file_content = self.read_file(path)
            init_line = 1
            if view_range:
                if len(view_range) != 2 or not all(isinstance(i, int) for i in view_range):
                    raise ToolError(""Invalid `view_range`. It should be a list of two integers."")
                file_lines = file_content.split(""\n"")
                n_lines_file = len(file_lines)
                init_line, final_line = view_range
                if init_line < 1 or init_line > n_lines_file:
                    raise ToolError(
                        f""Invalid `view_range`: {view_range}. Its first element `{init_line}` should be within the range of lines of the file: [1, {n_lines_file}]""
                    )
                if final_line > n_lines_file:
                    raise ToolError(
                        f""Invalid `view_range`: {view_range}. Its second element `{final_line}` should be smaller than or equal to the number of lines in the file: {n_lines_file}""
                    )
                if final_line != -1 and final_line < init_line:
                    raise ToolError(
                        f""Invalid `view_range`: {view_range}. Its second element `{final_line}` should be larger or equal than its first `{init_line}`""
                    )

                if final_line == -1:
                    file_content = ""\n"".join(file_lines[init_line - 1:])
                else:
                    file_content = ""\n"".join(file_lines[init_line - 1 : final_line])
            logging.info(f""'view' command successful on file: {path}"")
            return ToolResult(output=self._make_output(file_content, str(path), init_line=init_line), error=None, base64_image=None)
        except ToolError as te:
            logging.error(f""ToolError in 'view': {te}"")
            return ToolResult(output=None, error=str(te), base64_image=None)
        except Exception as e:
            logging.error(f""Unexpected error in 'view': {e}"")
            return ToolResult(output=None, error=str(e), base64_image=None)

    def str_replace(self, path: Path, old_str: str, new_str: Optional[str]) -> ToolResult:
        """"""Implement the str_replace command, which replaces old_str with new_str in the file content.""""""
        logging.info(f""Executing 'str_replace' on path: {path} with old_str: '{old_str}' and new_str: '{new_str}'"")
        try:
            # Read the file content
            path = self.normalize_path(str(path))
            file_content = self.read_file(path).expandtabs()
            old_str = old_str.expandtabs()
            new_str = new_str.expandtabs() if new_str is not None else """"

            # Check if old_str is unique in the file
            occurrences = file_content.count(old_str)
            if occurrences == 0:
                raise ToolError(f""No replacement was performed, old_str '{old_str}' did not appear verbatim in {path}."")
            elif occurrences > 1:
                file_content_lines = file_content.split(""\n"")
                lines = [
                    idx + 1
                    for idx, line in enumerate(file_content_lines)
                    if old_str in line
                ]
                raise ToolError(
                    f""No replacement was performed. Multiple occurrences of old_str '{old_str}' in lines {lines}. Please ensure it is unique""
                )

            # Replace old_str with new_str
            new_file_content = file_content.replace(old_str, new_str)

            # Write the new content to the file
            self.write_file(path, new_file_content)

            # Save the content to history
            self._file_history[path].append(file_content)

            # Create a snippet of the edited section
            replacement_line = file_content.split(old_str)[0].count(""\n"")
            start_line = max(0, replacement_line - SNIPPET_LINES)
            end_line = replacement_line + SNIPPET_LINES + new_str.count(""\n"")
            snippet = ""\n"".join(new_file_content.split(""\n"")[start_line : end_line + 1])

            # Prepare the success message
            success_msg = f""The file {path} has been edited. ""
            success_msg += self._make_output(snippet, f""a snippet of {path}"", start_line + 1)
            success_msg += ""Review the changes and make sure they are as expected. Edit the file again if necessary.""

            logging.info(f""'str_replace' command successful on path: {path}"")
            return ToolResult(output=success_msg, error=None, base64_image=None)

        except ToolError as te:
            logging.error(f""ToolError in 'str_replace': {te}"")
            return ToolResult(output=None, error=str(te), base64_image=None)
        except Exception as e:
            logging.error(f""Unexpected error in 'str_replace': {e}"")
            return ToolResult(output=None, error=str(e), base64_image=None)

    def insert(self, path: Path, insert_line: int, new_str: str) -> ToolResult:
        """"""Implement the insert command, which inserts new_str at the specified line in the file content.""""""
        logging.info(f""Executing 'insert' on path: {path} at line: {insert_line} with new_str: '{new_str}'"")
        try:
            path = self.normalize_path(str(path))
            file_text = self.read_file(path).expandtabs()
            new_str = new_str.expandtabs()
            file_text_lines = file_text.split(""\n"")
            n_lines_file = len(file_text_lines)

            if insert_line < 0 or insert_line > n_lines_file:
                raise ToolError(
                    f""Invalid `insert_line` parameter: {insert_line}. It should be within the range of lines of the file: [0, {n_lines_file}]""
                )

            new_str_lines = new_str.split(""\n"")
            new_file_text_lines = (
                file_text_lines[:insert_line]
                + new_str_lines
                + file_text_lines[insert_line:]
            )
            snippet_lines = (
                file_text_lines[max(0, insert_line - SNIPPET_LINES) : insert_line]
                + new_str_lines
                + file_text_lines[insert_line : insert_line + SNIPPET_LINES]
            )

            new_file_text = ""\n"".join(new_file_text_lines)
            snippet = ""\n"".join(snippet_lines)

            self.write_file(path, new_file_text)
            self._file_history[path].append(file_text)

            success_msg = f""The file {path} has been edited. ""
            success_msg += self._make_output(
                snippet,
                ""a snippet of the edited file"",
                max(1, insert_line - SNIPPET_LINES + 1),
            )
            success_msg += ""Review the changes and make sure they are as expected (correct indentation, no duplicate lines, etc). Edit the file again if necessary.""

            logging.info(f""'insert' command successful on path: {path}"")
            return ToolResult(output=success_msg, error=None, base64_image=None)

        except ToolError as te:
            logging.error(f""ToolError in 'insert': {te}"")
            return ToolResult(output=None, error=str(te), base64_image=None)
        except Exception as e:
            logging.error(f""Unexpected error in 'insert': {e}"")
            return ToolResult(output=None, error=str(e), base64_image=None)

    def undo_edit(self, path: Path) -> ToolResult:
        """"""Implement the undo_edit command.""""""
        logging.info(f""Executing 'undo_edit' on path: {path}"")
        try:
            path = self.normalize_path(str(path))
            if not self._file_history[path]:
                raise ToolError(f""No edit history found for {path}."")

            old_text = self._file_history[path].pop()
            self.write_file(path, old_text)

            success_msg = f""Last edit to {path} undone successfully. {self._make_output(old_text, str(path))}""

            logging.info(f""'undo_edit' command successful on path: {path}"")
            return ToolResult(output=success_msg, error=None, base64_image=None)

        except ToolError as te:
            logging.error(f""ToolError in 'undo_edit': {te}"")
            return ToolResult(output=None, error=str(te), base64_image=None)
        except Exception as e:
            logging.error(f""Unexpected error in 'undo_edit': {e}"")
            return ToolResult(output=None, error=str(e), base64_image=None)

    def read_file(self, path: Path) -> str:
        """"""Read the content of a file.""""""
        path = self.normalize_path(str(path))
        try:
            return path.read_text(encoding=""utf-8"").encode('ascii', errors='replace').decode('ascii')
        except Exception as e:
            logging.error(f""Error reading file {path}: {e}"")
            raise ToolError(f""Ran into {e} while trying to read {path}"") from None

    def write_file(self, path: Path, file: str):
        """"""Write the content of a file to a given path; raise a ToolError if an error occurs.""""""
        path = self.normalize_path(str(path))
        try:
            path.write_text(file, encoding=""utf-8"")
            logging.info(f""File written successfully at {path}"")
        except Exception as e:
            logging.error(f""Error writing to file {path}: {e}"")
            raise ToolError(f""Ran into {e} while trying to write to {path}"") from None

    def _make_output(
        self,
        file_content: str,
        file_descriptor: str,
        init_line: int = 1,
        expand_tabs: bool = True,
    ) -> str:
        """"""Generate output for the CLI based on the content of a file.""""""
        from .run import maybe_truncate  # Ensure this import is correct

        file_content = maybe_truncate(file_content)
        if expand_tabs:
            file_content = file_content.expandtabs()
        file_content = ""\n"".join(
            [
                f""{i + init_line:6}\t{line}""
                for i, line in enumerate(file_content.split(""\n""))
            ]
        )
        return (
            f""Here's the result of running `cat -n` on {file_descriptor}:\n""
            + file_content
            + ""\n""
        )
"
c:\mygit\compuse\computer_use_demo\loop.py,"#loop.py
""""""
Agentic sampling loop that calls the Anthropic API and local implementation of anthropic-defined computer use tools.
""""""
from icecream import ic
from datetime import datetime
from typing import cast, List, Optional, Any
from pathlib import Path
from anthropic import APIResponse
from anthropic.types.beta import BetaContentBlock
import hashlib
import base64
import os
import asyncio  
import pyautogui
from rich import print as rr
from icecream import install
import pysnooper
from rich.prompt import Prompt
# load the API key from the environment
from dotenv import load_dotenv
from anthropic import (
    Anthropic,
)
from anthropic.types.beta import (
    BetaCacheControlEphemeralParam,
    BetaMessageParam,
    BetaTextBlockParam,
    BetaToolResultBlockParam,
)

from tools import BashTool, ComputerTool, EditTool, ToolCollection, ToolResult, GetExpertOpinionTool, WebNavigatorTool, GoToURLReportsTool, WindowsNavigationTool

load_dotenv()
install()
import json

ICECREAM_OUTPUT_FILE = ""debug_log.json""
RR=False  
# append ICECREAM_OUTPUT_FILE to the end of ICECREAM_OUTPUT_FILE.archive and clear the file
if os.path.exists(ICECREAM_OUTPUT_FILE):
    with open(ICECREAM_OUTPUT_FILE, 'r') as f:
        lines = f.readlines()
    with open(ICECREAM_OUTPUT_FILE + '.archive.json', 'a') as f:
        for line in lines:
            f.write(line)
    with open(ICECREAM_OUTPUT_FILE, 'w') as f:
        f.write('')

def write_to_file(s, file_path=ICECREAM_OUTPUT_FILE):
    """"""
    Write debug output to a file, formatting JSON content in a pretty way.
    """"""
    lines = s.split('\n')
    formatted_lines = []
    
    for line in lines:
        if ""tool_input:"" in line:
            try:
                # Extract JSON part from the line
                json_part = line.split(""tool_input: "")[1]
                # Parse and pretty-print the JSON
                json_obj = json.loads(json_part)
                pretty_json = json.dumps(json_obj, indent=4)
                formatted_lines.append(""tool_input: "" + pretty_json)
            except (IndexError, json.JSONDecodeError):
                # If parsing fails, just append the original line
                formatted_lines.append(line)
        else:
            formatted_lines.append(line)
    
    # Write to file
    with open(file_path, 'a', encoding=""utf-8"") as f:
        f.write('\n'.join(formatted_lines))
        f.write('\n' + '-' * 80 + '\n')  # Add separator between entries

# Configure icecream
ic.configureOutput(includeContext=True, outputFunction=write_to_file)
# Define the system prompt
# read the system prompt from a file named system_prompt.md
with open(r""C:\mygit\compuse\computer_use_demo\system_prompt.md"", 'r',encoding=""utf-8"") as f:
    SYSTEM_PROMPT = f.read()


class OutputManager:
    """"""Manages and formats tool outputs and responses.""""""
    def __init__(self, image_dir: Optional[Path] = None ):
        # Set up image directory
        self.image_dir = image_dir
        self.image_dir.mkdir(parents=True, exist_ok=True)
        self.image_counter = 0

    def save_image(self, base64_data: str) -> Optional[Path]:
        """"""Save base64 image data to file and return path.""""""
        self.image_counter += 1
        timestamp = datetime.now().strftime(""%Y%m%d_%H%M%S"")
        # Create a short hash of the image data for uniqueness
        image_hash = hashlib.md5(base64_data.encode()).hexdigest()[:8]
        image_path = self.image_dir / f""image_{timestamp}_{image_hash}.png""

        try:
            image_data = base64.b64decode(base64_data)
            with open(image_path, 'wb') as f:
                f.write(image_data)
            return image_path
        except Exception as e:
            ic(f""Error saving image: {e}"")
            return None

    def format_tool_output(self, result: ToolResult, tool_name: str) -> None:
        """"""Format and print tool output without base64 data.""""""
        rr(""\n[bold blue]Tool Execution[/bold blue] 🛠️"")
        rr(f""[blue]Tool Name:[/blue] {tool_name}"")

        if isinstance(result, str):
            rr(f""[red]Error:[/red] {result}"")
        else:
            if result.output:
                # Safely truncate long output
                output_text = result.output
                if len(output_text) > 500:
                    output_text = output_text[:200] + ""/n.../n"" + output_text[-200:]
                rr(f""[green]Output:[/green] {output_text}"")
            
            if result.base64_image:
                image_path = self.save_image(result.base64_image)
                if image_path:
                    rr(f""[green]📸 Screenshot saved to {image_path}[/green]"")
                else:
                    rr(""[red]Failed to save screenshot[/red]"")

    def format_api_response(self, response: APIResponse) -> None:
        """"""Format and print API response.""""""
        rr(""\n[bold purple]Assistant Response[/bold purple] 🤖"")
        if hasattr(response.content[0], 'text'):
            text = response.content[0].text
            if len(text) > 500:
                text = text[:300] + ""..."" + text[-300:]
            rr(f""[purple]{text}[/purple]"")

    def format_content_block(self, block: BetaContentBlock) -> None:
        """"""Format and print content block.""""""
        if getattr(block, 'type', None) == ""tool_use"":
            ic(f""\nTool Use: {block.name}"")
            # Only print non-image related inputs
            safe_input = {k: v for k, v in block.input.items()
                         if not isinstance(v, str) or len(v) < 1000}
            ic(f""Input: {safe_input}"")
        elif hasattr(block, 'text'):
            ic(f""\nText: {block.text}"")

    def format_recent_conversation(self, messages: List[BetaMessageParam], num_recent: int = 2) -> None:
        """"""Format and print the most recent conversation exchanges.""""""
        rr(""\n[bold yellow]Recent Conversation[/bold yellow] 💭"")
        
        # Get the most recent messages
        recent_messages = messages[-num_recent*2:] if len(messages) > num_recent*2 else messages
        
        for msg in recent_messages:
            if msg['role'] == 'user':
                rr(""\n[bold green]User[/bold green] 👤"")
                content = msg['content']
                if isinstance(content, list):
                    for content_block in content:
                        if isinstance(content_block, dict):
                            if content_block.get(""type"") == ""tool_result"":
                                rr(f""[green]Tool Result:[/green]"")
                                for item in content_block.get(""content"", []):
                                    if item.get(""type"") == ""text"":
                                        text = item.get(""text"", """")
                                        if len(text) > 500:
                                            text = text[:200] + ""/n.../n"" + text[-200:]
                                        rr(f""[green]{text}[/green]"")
                                    elif item.get(""type"") == ""image"":
                                        rr(""[dim]📸 (Screenshot captured)[/dim]"")
                else:
                    if isinstance(content, str):
                        if len(content) > 500:
                            content = content[:300] + ""..."" + content[-300:]
                        rr(f""[green]{content}[/green]"")
            
            elif msg['role'] == 'assistant':
                rr(""\n[bold blue]Assistant[/bold blue] 🤖"")
                content = msg['content']
                if isinstance(content, list):
                    for content_block in content:
                        if isinstance(content_block, dict):
                            if content_block.get(""type"") == ""text"":
                                text = content_block.get(""text"", """")
                                if len(text) > 500:
                                    text = text[:400] + ""..."" + text[-400:]
                                rr(f""[blue]{text}[/blue]"")
                            elif content_block.get(""type"") == ""tool_use"":
                                rr(f""[cyan]Using tool:[/cyan] {content_block.get('name')}"")
                                tool_input = content_block.get('input', """")
                                # if isinstance(tool_input, str) and len(tool_input) > 500:
                                    # tool_input = tool_input[:200] + ""/n.../"" + tool_input[-200:]
                                # rr(f""[cyan]With input:[/cyan] {tool_input}"")
                                if isinstance(tool_input, str):
                                    # try to load as json
                                    try:
                                        tool_input = json.loads(tool_input)
                                        rr(f""[cyan]With input:[/cyan]"")
                                        for key, value in tool_input.items():
                                            if isinstance(value, str) and len(value) > 500:
                                                rr(f""[cyan]{key}:[/cyan] {value[:200] + '/n.../n'  + value[-200:]}"")
                                            else:
                                                rr(f""[cyan]{key}:[/cyan] {value}"")  
                                    except json.JSONDecodeError:
                                        if isinstance(tool_input, str):
                                            tool_input = tool_input[:200] + ""/n.../"" + tool_input[-200:]
                                        rr(f""[cyan]With input:[/cyan] {tool_input}"")
                                        

                elif isinstance(content, str):
            
                    if len(content) > 500:
                        content = content[:200] + ""/n.../n"" + content[-200:]
                    rr(f""[blue]{content}[/blue]"")

        rr(""\n"" + ""=""*50 + ""\n"")

def _make_api_tool_result(result: ToolResult, tool_use_id: str) -> dict:
    """"""Convert tool result to API format.""""""
    tool_result_content = []
    is_error = False
    ic(result)
    # if result is a ToolFailure, print the error message
    if isinstance(result, str):
        ic(f""Tool Failure: {result}"")
        is_error = True
        tool_result_content.append({
            ""type"": ""text"",
            ""text"": result
        })
    else:
        if result.output:
            tool_result_content.append({
                ""type"": ""text"",
                ""text"": result.output
            })
        if result.base64_image:
            tool_result_content.append({
                ""type"": ""image"",
                ""source"": {
                    ""type"": ""base64"",
                    ""media_type"": ""image/png"",
                    ""data"": result.base64_image,
                }
            })

    
    return {
        ""type"": ""tool_result"",
        ""content"": tool_result_content,
        ""tool_use_id"": tool_use_id,
        ""is_error"": is_error,
    }

COMPUTER_USE_BETA_FLAG = ""computer-use-2024-10-22""
PROMPT_CACHING_BETA_FLAG = ""prompt-caching-2024-07-31""

class TokenTracker:
    """"""Tracks total token usage across all iterations.""""""
    def __init__(self):
        self.total_cache_creation = 0
        self.total_cache_retrieval = 0
        self.total_input = 0
        self.total_output = 0
    
    def update(self, response):
        """"""Update totals with new response usage.""""""
        self.total_cache_creation += response.usage.cache_creation_input_tokens
        self.total_cache_retrieval += response.usage.cache_read_input_tokens
        self.total_input += response.usage.input_tokens
        self.total_output += response.usage.output_tokens
    
    def display(self):
        """"""Display total token usage.""""""
        rr(""\n[bold yellow]Total Token Usage Summary[/bold yellow] 📊"")
        rr(f""[yellow]Total Cache Creation Tokens:[/yellow] {self.total_cache_creation:,}"")
        rr(f""[yellow]Total Cache Retrieval Tokens:[/yellow] {self.total_cache_retrieval:,}"")
        rr(f""[yellow]Total Input Tokens:[/yellow] {self.total_input:,}"")
        rr(f""[yellow]Total Output Tokens:[/yellow] {self.total_output:,}"")
        rr(f""[bold yellow]Total Tokens Used:[/bold yellow] {self.total_cache_creation + self.total_cache_retrieval + self.total_input + self.total_output:,}"")

# Add near the top of the file
JOURNAL_FILE = ""journal/journal.log""
JOURNAL_MODEL = ""claude-3-5-haiku-latest""
JOURNAL_MAX_TOKENS = 1500
JOURNAL_SYSTEM_PROMPT_FILE  = ""journal/journal_system_prompt.md""
with open(JOURNAL_SYSTEM_PROMPT_FILE, 'r', encoding=""utf-8"") as f:
    JOURNAL_SYSTEM_PROMPT = f.read()

async def create_journal_entry(entry_number: int, messages: List[BetaMessageParam], response: APIResponse, client: Anthropic):
    """"""Creates a concise journal entry using Claude Haiku.""""""
    try:
        # Extract last interaction
        user_message = """"
        assistant_response = """"
        
        # Get most recent messages
        for msg in reversed(messages[-4:]):  # Only look at last 2 exchanges
            if msg['role'] == 'user' and not user_message:
                if isinstance(msg['content'], list):
                    for content_block in msg['content']:
                        if isinstance(content_block, dict):
                            if content_block.get(""type"") == ""text"":
                                user_message = content_block.get(""text"", """")
                            elif content_block.get(""type"") == ""tool_result"":
                                user_message = "" "".join([
                                    item.get(""text"", """") 
                                    for item in content_block.get(""content"", [])
                                    if isinstance(item, dict) and item.get(""type"") == ""text""
                                ])
                elif isinstance(msg['content'], str):
                    user_message = msg['content']
                    
        # Get the assistant's response text
        if response and response.content:
            assistant_texts = []
            for block in response.content:
                if hasattr(block, 'text'):
                    assistant_texts.append(block.text)
            assistant_response = "" "".join(assistant_texts)

        # Skip if missing content
        if not user_message or not assistant_response:
            ic(""Skipping journal entry - missing content"")
            return

        # Create prompt
        journal_prompt = f""Summarize this interaction:\nUser: {user_message}\nAssistant: {assistant_response}""
        rr(f""Journal Prompt:\n {journal_prompt}"")
        # Get summary using Haiku - Add await here
        haiku_response = client.messages.create(
            model=JOURNAL_MODEL,
            max_tokens=JOURNAL_MAX_TOKENS,
            messages=[{
                ""role"": ""user"",
                ""content"": journal_prompt
            }],
            system=JOURNAL_SYSTEM_PROMPT
        )

        summary = haiku_response.content[0].text.strip()
        if not summary:
            ic(""Skipping journal entry - no summary generated"")
            return
        rr(f""Journal Summary:\n {summary}"")
        # Format entry
        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")
        journal_entry = f""\nEntry #{entry_number} - {timestamp}\n{summary}\n-------------------\n""

        # Ensure directory exists
        os.makedirs(os.path.dirname(JOURNAL_FILE), exist_ok=True)

        # Write entry
        with open(JOURNAL_FILE, 'a', encoding='utf-8') as f:
            f.write(journal_entry)
            
        ic(f""Created journal entry #{entry_number}"")

    except Exception as e:
        ic(f""Error creating journal entry: {str(e)}"")



async def sampling_loop(*, model: str, messages: List[BetaMessageParam], api_key: str, max_tokens: int = 8000,) -> List[BetaMessageParam]:
    ic(messages)
    try:
        # Initialize tools with proper error handling
        tool_collection = ToolCollection(
            BashTool(),
            EditTool(),
            GetExpertOpinionTool(),
            ComputerTool(),
            WebNavigatorTool(),
            WindowsNavigationTool()
        )
        ic(tool_collection)            
        
        system = BetaTextBlockParam(
            type=""text"",
            text=SYSTEM_PROMPT,  
        )
        
        output_manager = OutputManager(image_dir=Path('logs/computer_tool_images'))
        client = Anthropic(api_key=api_key)
        i = 0
        ic(i)
        running = True
        token_tracker = TokenTracker()
        
        # Add journal entry counter
        journal_entry_count = 1
        if os.path.exists(JOURNAL_FILE):
            with open(JOURNAL_FILE, 'r') as f:
                journal_entry_count = sum(1 for line in f if line.startswith(""Entry #"")) + 1

        while running:
            rr(f""\n[bold yellow]Iteration {i}[/bold yellow] 🔄"")
            enable_prompt_caching = True
            betas = [COMPUTER_USE_BETA_FLAG, PROMPT_CACHING_BETA_FLAG]
            image_truncation_threshold = 1
            only_n_most_recent_images = 2
            if i % 2 == 0:
                await asyncio.sleep(10) 
            i+=1
            if enable_prompt_caching:
                _inject_prompt_caching(messages)
                # Is it ever worth it to bust the cache with prompt caching?
                image_truncation_threshold = 1
                system=[
                            {
                                ""type"": ""text"",
                                ""text"": SYSTEM_PROMPT,
                                ""cache_control"": {""type"": ""ephemeral""}
                            },
                        ]

            if only_n_most_recent_images:
                _maybe_filter_to_n_most_recent_images(
                    messages,
                    only_n_most_recent_images,
                    min_removal_threshold=image_truncation_threshold,
                )

            try:
                tool_collection.to_params()
                # ic(f""Messages: {messages}"")
                if i % 2 == 0:
                    # wait for 20 seconds
                    await asyncio.sleep(10) 
                ic(messages)
                response = client.beta.messages.create(
                    max_tokens=max_tokens,
                    messages=messages,
                    model=model,
                    system=system,
                    tools=tool_collection.to_params(),
                    betas=betas,
                    )
                # Update token tracker
                token_tracker.update(response)
                
                # Display current iteration tokens
                rr(f""Cache Creation Tokens: {response.usage.cache_creation_input_tokens}"")
                rr(f""Cache Retrieval Tokens: {response.usage.cache_read_input_tokens}"")
                rr(f""Output Tokens: {response.usage.output_tokens}"")
                rr(f""Input Tokens: {response.usage.input_tokens}"")
                
                ic(f""Response: {response}"")
                # output_manager.format_api_response(response)
                
                # Convert response content to params format
                response_params = []
                for block in response.content:
                    if hasattr(block, 'text'):
                        output_manager.format_api_response(response)
                        response_params.append({
                            ""type"": ""text"",
                            ""text"": block.text
                        })
                    elif getattr(block, 'type', None) == ""tool_use"":
                        response_params.append({
                            ""type"": ""tool_use"",
                            ""name"": block.name,
                            ""id"": block.id,
                            ""input"": block.input
                        })
                # Append assistant message with full response content
                messages.append({
                    ""role"": ""assistant"",
                    ""content"": response_params
                })
                # Format the recent conversation after each response
                output_manager.format_recent_conversation(messages)
                
                # Process tool uses and collect results
                tool_result_content: list[BetaToolResultBlockParam] = []
                for content_block in response_params:
                    output_manager.format_content_block(content_block)
                    if content_block[""type""] == ""tool_use"":
                        ic(f""Tool Use: {response_params}"")
                        result = await tool_collection.run(
                            name=content_block[""name""],
                            tool_input=content_block[""input""],
                        )
                        ic.configureOutput(includeContext=True, outputFunction=write_to_file,argToStringFunction=repr)
                        ic(content_block)
                        output_manager.format_tool_output(result, content_block[""name""])
                        tool_result = _make_api_tool_result(result, content_block[""id""])
                        ic(tool_result)
                        tool_result_content.append(tool_result)
                # If no tool results, we're done
                if not tool_result_content:
                    rr(""\n[bold yellow]Awaiting User Input[/bold yellow] ⌨️"")
                    task = Prompt.ask(""What would you like to do next? Enter 'no' to exit"")
                    if task.lower() in [""no"", ""n""]:
                        running = False
                    messages.append({""role"": ""user"", ""content"": task})
                else:
                    # Append tool results as user message
                    messages.append({
                        ""role"": ""user"",
                        ""content"": tool_result_content
                    })
                rr(f""Creating journal entry #{journal_entry_count}"")
                # After processing the response and before the next iteration, add journal entry
                
                try:
                    await create_journal_entry(
                        entry_number=journal_entry_count,
                        messages=messages,
                    response=response,
                        client=client
                    )
                    journal_entry_count += 1
                except Exception as e:
                    ic(f""Error creating journal entry: {str(e)}"")

            
            except UnicodeEncodeError as ue:
                ic(f""UnicodeEncodeError: {ue}"")
                rr(f""Unicode encoding error: {ue}"")
                rr(f""ascii: {ue.args[1].encode('ascii', errors='replace').decode('ascii')}"")
                # Handle or skip the problematic message
                break        
            except Exception as e:
                ic(f""Error in sampling loop: {str(e).encode('ascii', errors='replace').decode('ascii')}"")
                ic(f""The error occurred at the following message: {messages[-1]} and line: {e.__traceback__.tb_lineno}"")
                ic(e.__traceback__.tb_frame.f_locals)
                raise
        # Display total token usage before returning
        token_tracker.display()
        return messages

    except Exception as e:
        ic(e.__traceback__.tb_lineno)
        ic(e.__traceback__.tb_lasti)
        ic(e.__traceback__.tb_frame.f_code.co_filename)
        ic(e.__traceback__.tb_frame)
        ic(f""Error initializing sampling loop: {str(e)}"")
        raise  # Re-raise the exception after logging it


def _inject_prompt_caching(
    messages: list[BetaMessageParam],
):
    """"""
    Set cache breakpoints for the 3 most recent turns
    one cache breakpoint is left for tools/system prompt, to be shared across sessions
    """"""

    breakpoints_remaining = 2
    for message in reversed(messages):
        if message[""role""] == ""user"" and isinstance(
            content := message[""content""], list
        ):
            if breakpoints_remaining:
                breakpoints_remaining -= 1
                content[-1][""cache_control""] = BetaCacheControlEphemeralParam(
                    {""type"": ""ephemeral""}
                )
            else:
                # rr(f""Removing cache control from message: {content[-1]}"")
                content[-1].pop(""cache_control"", None)
                # we'll only every have one extra turn per loop
                break
def _maybe_filter_to_n_most_recent_images(
    messages: list[BetaMessageParam],
    images_to_keep: int,
    min_removal_threshold: int,
):
    """"""
    With the assumption that images are screenshots that are of diminishing value as
    the conversation progresses, remove all but the final `images_to_keep` tool_result
    images in place, with a chunk of min_removal_threshold to reduce the amount we
    break the implicit prompt cache.
    """"""
    if images_to_keep is None:
        return messages

    tool_result_blocks = cast(
        list[BetaToolResultBlockParam],
        [
            item
            for message in messages
            for item in (
                message[""content""] if isinstance(message[""content""], list) else []
            )
            if isinstance(item, dict) and item.get(""type"") == ""tool_result""
        ],
    )

    total_images = sum(
        1
        for tool_result in tool_result_blocks
        for content in tool_result.get(""content"", [])
        if isinstance(content, dict) and content.get(""type"") == ""image""
    )

    images_to_remove = total_images - images_to_keep
    # for better cache behavior, we want to remove in chunks
    images_to_remove -= images_to_remove % min_removal_threshold

    for tool_result in tool_result_blocks:
        if isinstance(tool_result.get(""content""), list):
            new_content = []
            for content in tool_result.get(""content"", []):
                if isinstance(content, dict) and content.get(""type"") == ""image"":
                    if images_to_remove > 0:
                        images_to_remove -= 1
                        continue
                new_content.append(content)
            tool_result[""content""] = new_content

async def run_sampling_loop(task: str) -> List[BetaMessageParam]:
    """"""Run the sampling loop with clean output handling.""""""
    api_key = os.getenv(""ANTHROPIC_API_KEY"")
    messages = []
    ic(messages)
    running = True
    if not api_key:
        raise ValueError(""API key not found. Please set the ANTHROPIC_API_KEY environment variable."")
    ic(messages.append({""role"": ""user"",""content"": task}))
    messages =  await sampling_loop(
                                model=""claude-3-5-sonnet-latest"",
                                messages=messages,
                                api_key=api_key,
                            )
    return messages

async def main_async():
    """"""Async main function with proper error handling.""""""
    # read the task from prompt.md
    with open(r""C:\mygit\compuse\computer_use_demo\prompt.md"", 'r',encoding=""utf-8"") as f:
        task = f.read() 
    # task = input(""Enter the task you want to perform: "")
    # use rich.prompt to get the task
    # task = Prompt.ask(""Enter the task you want to perform:"")
    # task = '''I need you to get an expert opinion on how to test, run,implement use cases and test the functionality for the code in the file C:/repo/code_test/code_context_manager.py . The commands you run will be from a different directory so please use absolute paths for EVERYTHING!'''
    try:
        messages = await run_sampling_loop(task)
        rr(""\nTask Completed Successfully"")
        
        # The token summary will be displayed here from sampling_loop
        
        rr(""\nFinal Messages:"")
        for msg in messages:
            rr(f""\n{msg['role'].upper()}:"")
            # If content is a list of dicts (like tool_result), format accordingly
            if isinstance(msg['content'], list):
                for content_block in msg['content']:
                    if isinstance(content_block, dict):
                        if content_block.get(""type"") == ""tool_result"":
                            rr(f""Tool Result [ID: {content_block.get('name', 'unknown')}]:"")
                            for item in content_block.get(""content"", []):
                                if item.get(""type"") == ""text"":
                                    rr(f""Text: {item.get('text')}"")
                                elif item.get(""type"") == ""image"":
                                    rr(""Image Source: base64 source too big"")#{item.get('source', {}).get('data')}"")
                        else:
                            for key, value in content_block.items():
                                rr(f""{key}: {value}"")
                    else:
                        rr(content_block)
            else:
                rr(msg['content'])

    except Exception as e:
        rr(f""Error during execution: {e}"")

def main():
    """"""Main entry point with proper async handling.""""""

    asyncio.run(main_async())

if __name__ == ""__main__"":
    main()"
c:\mygit\compuse\computer_use_demo\__init__.py,
c:\mygit\compuse\computer_use_demo\tools\base.py,"## base.py
from abc import ABCMeta, abstractmethod
from dataclasses import dataclass, fields, replace
from typing import Any, Optional, Dict



class BaseAnthropicTool(metaclass=ABCMeta):
    """"""Base class for all tools.""""""

    def __init__(self, input_schema: Optional[Dict[str, Any]] = None):
        self.input_schema = input_schema or {
            ""type"": ""object"",
            ""properties"": {},
            ""required"": []
        }

    @property
    @abstractmethod
    def name(self) -> str:
        """"""The name of the tool.""""""
        pass

    @property
    @abstractmethod
    def description(self) -> str:
        """"""A description of what the tool does.""""""
        pass

    @abstractmethod
    def __call__(self, **kwargs) -> Any:
        """"""Execute the tool with the given arguments.""""""
        pass

    def to_params(self) -> Dict[str, Any]:
        """"""Convert the tool to xAI API parameters.""""""
        return {
            ""type"": ""function"",
            ""function"": {
                ""name"": self.name,
                ""description"": self.description,
                ""parameters"": self.input_schema
            }
        }


@dataclass(kw_only=True, frozen=True)
class ToolResult:
    """"""Represents the result of a tool execution.""""""

    output: Optional[str] = None
    error: Optional[str] = None
    base64_image: Optional[str] = None
    system: Optional[str] = None

    def __bool__(self):
        return any(getattr(self, field.name) for field in fields(self))

    def __add__(self, other: ""ToolResult""):
        def combine_fields(
            field: str | None, other_field: str | None, concatenate: bool = True
        ):
            if field and other_field:
                if concatenate:
                    return field + other_field
                raise ValueError(""Cannot combine tool results"")
            return field or other_field

        return ToolResult(
            output=combine_fields(self.output, other.output),
            error=combine_fields(self.error, other.error),
            base64_image=combine_fields(self.base64_image, other.base64_image, False),
            system=combine_fields(self.system, other.system),
        )

    def replace(self, **kwargs):
        """"""Returns a new ToolResult with the given fields replaced.""""""
        return replace(self, **kwargs)


class CLIResult(ToolResult):
    """"""A ToolResult that can be rendered as a CLI output.""""""
    pass


class ToolFailure(ToolResult):
    """"""A ToolResult that represents a failure.""""""
    pass


@dataclass(kw_only=True, frozen=True)
class ToolError(Exception):
    """"""Raised when a tool encounters an error.""""""
    message: str

    def __init__(self, message: str):
        object.__setattr__(self, 'message', message)
        super().__init__(message)

    def __str__(self):
        return self.message"
c:\mygit\compuse\computer_use_demo\tools\bash.py,"## bash.py
import asyncio
from typing import ClassVar, Literal
from anthropic.types.beta import BetaToolBash20241022Param
# from torch import error
from .base import BaseAnthropicTool, CLIResult, ToolError, ToolResult
import platform
# Using subprocess directly for shell commands
from rich import print as rr
class BashTool(BaseAnthropicTool):
    description=""""""
    A tool that allows the agent to run bash commands. On Windows it uses PowerShell
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    name: ClassVar[Literal[""bash""]] = ""bash""
    api_type: ClassVar[Literal[""bash_20241022""]] = ""bash_20241022""

    async def __call__(
        self, command: str | None = None, **kwargs
    ):
        if command is not None:
             if platform.system() == 'Windows':
                 
                 command = f""powershell.exe -command cd c:/repo && {command}"" # Run PowerShell commands on Windows
             return await self._run_command(command)

        raise ToolError(""no command provided."")

    async def _run_command(self, command: str):
        """"""Execute a command in the shell.""""""
        try:
            rr(command)
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                shell=True
            )
            stdout, stderr = await process.communicate()

            output = stdout.decode().strip() if stdout else """"
            error = stderr.decode().strip() if stderr else None
            rr(output)
            if error:
                rr(error)

            return CLIResult(output=output, error=error)

        except Exception as e:

            return ToolResult(output=None, error=str(e))

    def to_params(self) -> BetaToolBash20241022Param:
        return {
            ""type"": self.api_type,
            ""name"": self.name,
        }   
    

"
c:\mygit\compuse\computer_use_demo\tools\bash_original.py,"import asyncio
import os
from typing import ClassVar, Literal

from anthropic.types.beta import BetaToolBash20241022Param

from .base import BaseAnthropicTool, CLIResult, ToolError, ToolResult


class _BashSession:
    """"""A session of a bash shell.""""""

    _started: bool
    _process: asyncio.subprocess.Process

    command: str = ""/bin/bash""
    _output_delay: float = 0.2  # seconds
    _timeout: float = 120.0  # seconds
    _sentinel: str = ""<<exit>>""

    def __init__(self):
        self._started = False
        self._timed_out = False

    async def start(self):
        if self._started:
            return

        self._process = await asyncio.create_subprocess_shell(
            self.command,
            preexec_fn=os.setsid,
            shell=True,
            bufsize=0,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        self._started = True

    def stop(self):
        """"""Terminate the bash shell.""""""
        if not self._started:
            raise ToolError(""Session has not started."")
        if self._process.returncode is not None:
            return
        self._process.terminate()

    async def run(self, command: str):
        """"""Execute a command in the bash shell.""""""
        if not self._started:
            raise ToolError(""Session has not started."")
        if self._process.returncode is not None:
            return ToolResult(
                system=""tool must be restarted"",
                error=f""bash has exited with returncode {self._process.returncode}"",
            )
        if self._timed_out:
            raise ToolError(
                f""timed out: bash has not returned in {self._timeout} seconds and must be restarted"",
            )

        # we know these are not None because we created the process with PIPEs
        assert self._process.stdin
        assert self._process.stdout
        assert self._process.stderr

        # send command to the process
        self._process.stdin.write(
            command.encode() + f""; echo '{self._sentinel}'\n"".encode()
        )
        await self._process.stdin.drain()

        # read output from the process, until the sentinel is found
        try:
            async with asyncio.timeout(self._timeout):
                while True:
                    await asyncio.sleep(self._output_delay)
                    # if we read directly from stdout/stderr, it will wait forever for
                    # EOF. use the StreamReader buffer directly instead.
                    output = self._process.stdout._buffer.decode()  # pyright: ignore[reportAttributeAccessIssue]
                    if self._sentinel in output:
                        # strip the sentinel and break
                        output = output[: output.index(self._sentinel)]
                        break
        except asyncio.TimeoutError:
            self._timed_out = True
            raise ToolError(
                f""timed out: bash has not returned in {self._timeout} seconds and must be restarted"",
            ) from None

        if output.endswith(""\n""):
            output = output[:-1]

        error = self._process.stderr._buffer.decode()  # pyright: ignore[reportAttributeAccessIssue]
        if error.endswith(""\n""):
            error = error[:-1]

        # clear the buffers so that the next output can be read correctly
        self._process.stdout._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]
        self._process.stderr._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]

        return CLIResult(output=output, error=error)


class BashTool(BaseAnthropicTool):
    """"""
    A tool that allows the agent to run bash commands.
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    _session: _BashSession | None
    name: ClassVar[Literal[""bash""]] = ""bash""
    api_type: ClassVar[Literal[""bash_20241022""]] = ""bash_20241022""

    def __init__(self):
        self._session = None
        super().__init__()

    async def __call__(
        self, command: str | None = None, restart: bool = False, **kwargs
    ):
        if restart:
            if self._session:
                self._session.stop()
            self._session = _BashSession()
            await self._session.start()

            return ToolResult(system=""tool has been restarted."")

        if self._session is None:
            self._session = _BashSession()
            await self._session.start()

        if command is not None:
            return await self._session.run(command)

        raise ToolError(""no command provided."")

    def to_params(self) -> BetaToolBash20241022Param:
        return {
            ""type"": self.api_type,
            ""name"": self.name,
        }
"
c:\mygit\compuse\computer_use_demo\tools\code_context_manager.py,"# code_context_manager.py

import os
import json
import re
import ast
import subprocess
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Set, Optional, List, Tuple

@dataclass
class CodeFile:
    name: str
    content: str
    version: int = 1
    last_modified: datetime = field(default_factory=datetime.now)
    dependencies: Set[str] = field(default_factory=set)
    description: Optional[str] = None

    def to_message(self) -> Dict[str, any]:
        """"""Convert CodeFile to a structured message for an LLM or any other consumer.""""""
        message_content = f""""""
        FILE CONTEXT:
        **{self.name}** (v{self.version})
        *Last Modified*: {self.last_modified.strftime('%Y-%m-%d %H:%M:%S')}
        *Dependencies*: {', '.join(self.dependencies) if self.dependencies else 'None'}
        *Description*: {self.description or 'No description provided.'}

        **Content:**
        ```python
        {self.content}
        ```
        """"""

        return {
            ""role"": ""user"",
            ""content"": [{
                ""type"": ""text"",
                ""text"": message_content
            }]
        }

def extract_code_blocks(response_text: str) -> List[Tuple[str, str]]:
    """"""
    Extracts code blocks from the response text.

    Returns a list of tuples containing the language and code.
    For example: [(""python"", ""def foo(): pass""), ...]
    """"""
    code_blocks = []
    # Regex to match code blocks with language specification
    pattern = re.compile(r""```(\w+)?\n([\s\S]*?)```"", re.MULTILINE)
    matches = pattern.findall(response_text)
    for lang, code in matches:
        language = lang.strip() if lang else ""plaintext""
        code_blocks.append((language, code.strip()))
    return code_blocks

def is_code_valid(code: str) -> bool:
    """"""
    Checks if the provided Python code is syntactically correct.
    """"""
    try:
        ast.parse(code)
        return True
    except SyntaxError as e:
        print(f""SyntaxError while parsing code: {e}"")
        return False

def replace_file(file_path: str, new_content: str) -> None:
    """"""
    Replaces the entire content of the specified file with new_content.
    """"""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    print(f""Replaced content of {file_path}"")

def insert_code_after_function(original_content: str, function_name: str, code_to_add: str) -> str:
    """"""
    Inserts code after the specified function in a Python file.
    """"""
    pattern = re.compile(rf""(def {re.escape(function_name)}\(.*?\):\s*[\s\S]*?)(?=def |\Z)"", re.MULTILINE)
    match = pattern.search(original_content)
    if match:
        insert_position = match.end()
        return original_content[:insert_position] + '\n\n' + code_to_add + original_content[insert_position:]
    else:
        # If function not found, append at the end
        return original_content + '\n\n' + code_to_add

def extract_single_code_block(code_block: str) -> Tuple[Optional[str], Optional[str]]:
    """"""
    Extracts a single code block's language and code.
    """"""
    match = re.match(r""```(\w+)?\n([\s\S]*?)```"", code_block, re.MULTILINE)
    if match:
        lang = match.group(1).strip() if match.group(1) else ""plaintext""
        code = match.group(2).strip()
        return lang, code
    return None, None

def commit_changes(message: str) -> None:
    """"""
    Commits changes to the git repository with the provided message.
    """"""
    try:
        subprocess.run([""git"", ""add"", "".""], check=True)
        subprocess.run([""git"", ""commit"", ""-m"", message], check=True)
        print(f""Changes committed: {message}"")
    except subprocess.CalledProcessError as e:
        print(f""Git commit failed: {e}"")

def run_tests() -> bool:
    """"""
    Runs the test suite and returns True if all tests pass.
    """"""
    try:
        subprocess.run([""pytest""], check=True)
        print(""All tests passed."")
        return True
    except subprocess.CalledProcessError:
        print(""Some tests failed."")
        return False

def revert_last_commit() -> None:
    """"""
    Reverts the last git commit.
    """"""
    try:
        subprocess.run([""git"", ""reset"", ""--hard"", ""HEAD~1""], check=True)
        print(""Reverted the last commit."")
    except subprocess.CalledProcessError as e:
        print(f""Failed to revert commit: {e}"")

class CodeContextManager:
    def __init__(self, persistence_file: Optional[str] = None):
        self.files: Dict[str, CodeFile] = {}
        self.persistence_file = persistence_file
        if self.persistence_file:
            self.load_from_disk()

    def update_file(self, 
                   name: str, 
                   content: str, 
                   dependencies: Optional[Set[str]] = None, 
                   description: Optional[str] = None) -> None:
        """"""Add or update a file in the context.""""""
        if name in self.files:
            existing_file = self.files[name]
            existing_file.version += 1
            existing_file.content = content
            existing_file.last_modified = datetime.now()
            if dependencies is not None:
                existing_file.dependencies = dependencies
            if description is not None:
                existing_file.description = description
            print(f""Updated file: {name} to version {existing_file.version}"")
        else:
            self.files[name] = CodeFile(
                name=name,
                content=content,
                dependencies=dependencies or set(),
                description=description
            )
            print(f""Added new file: {name}"")

        if self.persistence_file:
            self.save_to_disk()

    def get_context_messages(self) -> List[Dict[str, any]]:
        """"""Get all file contexts as messages.""""""
        return [file.to_message() for file in self.files.values()]

    def save_to_disk(self) -> None:
        """"""Persist the current code context to disk.""""""
        data = {
            name: {
                ""name"": file.name,
                ""content"": file.content,
                ""version"": file.version,
                ""last_modified"": file.last_modified.isoformat(),
                ""dependencies"": list(file.dependencies),
                ""description"": file.description
            } for name, file in self.files.items()
        }
        with open(self.persistence_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4)
        print(f""Saved code context to {self.persistence_file}"")

    def load_from_disk(self) -> None:
        """"""Load the code context from disk.""""""
        if not os.path.exists(self.persistence_file):
            print(f""Persistence file {self.persistence_file} does not exist. Starting fresh."")
            return

        with open(self.persistence_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            for name, file_data in data.items():
                self.files[name] = CodeFile(
                    name=file_data[""name""],
                    content=file_data[""content""],
                    version=file_data[""version""],
                    last_modified=datetime.fromisoformat(file_data[""last_modified""]),
                    dependencies=set(file_data[""dependencies""]),
                    description=file_data.get(""description"")
                )
        print(f""Loaded code context from {self.persistence_file}"")

    def remove_file(self, name: str) -> None:
        """"""Remove a file from the context.""""""
        if name in self.files:
            del self.files[name]
            print(f""Removed file: {name}"")
            if self.persistence_file:
                self.save_to_disk()
        else:
            print(f""Tried to remove non-existent file: {name}"")

    def apply_llm_response(self, response_text: str) -> None:
        """"""
        Parses the LLM response, extracts code blocks, and updates the relevant files.
        Assumes the LLM follows a specific format to indicate target files and update types.

        Example LLM response format:

        ### Update file1.py
        ```python
        def greet(name, greeting=""Hello""):
            return f""{greeting}, {name}!""
        ```

        ### Add to file2.py
        ```python
        def new_function():
            pass
        ```
        """"""
        # Split the response into sections based on filenames
        sections = re.split(r'###\s+(?:Update|Add)\s+(\S+)', response_text)
        
        # The split will result in a list where filenames are captured in group 1
        # Process in pairs: [text, filename, action, text, filename, action, ...]
        it = iter(sections)
        for section in it:
            if not section.strip():
                continue
            # Get filename
            filename = section.strip()
            # Get action (assume that 'Update' or 'Add' was matched before the filename)
            # Since regex does not capture action, infer it
            action_match = re.search(r'###\s+(Update|Add)\s+', section)
            action = ""full_replace"" if ""Update"" in section else ""add_code""
            
            # Get the next item which should be the code block
            try:
                code_block = next(it).strip()
                lang, code = extract_single_code_block(code_block)
                if not code:
                    print(f""No code found in section for {filename}. Skipping."")
                    continue
                if not is_code_valid(code):
                    print(f""Invalid code for {filename}. Skipping."")
                    continue

                if action == ""full_replace"":
                    self.replace_file_content(filename, code)
                    commit_changes(f""Replaced content of {filename}"")
                elif action == ""add_code"":
                    # Optionally, specify function or location
                    # For simplicity, appending to the end
                    self.add_code_to_file(filename, code)
                    commit_changes(f""Added code to {filename}"")
                
                # Run tests after each change
                if run_tests():
                    print(f""Changes to {filename} passed tests."")
                else:
                    print(f""Tests failed after changes to {filename}. Reverting."")
                    revert_last_commit()
            except StopIteration:
                break

    def replace_file_content(self, filename: str, new_content: str) -> None:
        """"""
        Replaces the entire content of the specified file.
        """"""
        file_path = os.path.join('code_files', filename)
        if os.path.exists(file_path):
            replace_file(file_path, new_content)
            self.update_file(
                name=filename,
                content=new_content,
                dependencies=self.extract_dependencies(new_content),
                description=self.files[filename].description  # Keep existing description
            )
        else:
            print(f""File {filename} does not exist. Creating a new one."")
            replace_file(file_path, new_content)
            self.update_file(
                name=filename,
                content=new_content,
                dependencies=self.extract_dependencies(new_content),
                description=""Automatically created file.""
            )

    def add_code_to_file(self, filename: str, code_to_add: str, function_name: Optional[str] = None) -> None:
        """"""
        Adds new code to an existing file. Optionally, specify the function name for better placement.
        """"""
        file_path = os.path.join('code_files', filename)
        if not os.path.exists(file_path):
            print(f""File {filename} does not exist. Creating a new one."")
            replace_file(file_path, code_to_add)
            self.update_file(
                name=filename,
                content=code_to_add,
                dependencies=self.extract_dependencies(code_to_add),
                description=""Automatically created file.""
            )
            return

        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        if function_name:
            # Insert code after the specified function
            updated_content = insert_code_after_function(original_content, function_name, code_to_add)
        else:
            # Append code at the end
            updated_content = original_content + '\n\n' + code_to_add

        replace_file(file_path, updated_content)

        self.update_file(
            name=filename,
            content=updated_content,
            dependencies=self.extract_dependencies(updated_content),
            description=self.files[filename].description
        )
        print(f""Added code to {filename}"")

    def extract_dependencies(self, content: str) -> Set[str]:
        """"""
        Extracts dependencies from the given Python file content.
        """"""
        dependencies = set()
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        dependencies.add(alias.name.split('.')[0] + '.py')
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        dependencies.add(node.module.split('.')[0] + '.py')
        except SyntaxError:
            pass
        # Filter dependencies to include only local files
        return {dep for dep in dependencies if dep in self.files}
"
c:\mygit\compuse\computer_use_demo\tools\code_tools.py,"from pydantic import BaseModel, Field, model_validator
from typing import List, Optional, Dict, Set
from pathlib import Path
import pandas as pd
import ast
from dataclasses import dataclass
import networkx as nx
import importlib
import importlib.metadata
import importlib.util
import os
import sys
from rich import print as rr
from importlib.metadata import distributions, version, PackageNotFoundError
from tqdm import tqdm
def get_stdlib_modules() -> Set[str]:
    """"""Get a set of standard library module names""""""
    stdlib_paths = {
        os.path.dirname(os.__file__),  # Standard library path
        os.path.dirname(importlib.__file__),  # Additional standard library path
    }
    
    stdlib_modules = set()
    for path in stdlib_paths:
        if os.path.exists(path):
            for item in os.listdir(path):
                name, ext = os.path.splitext(item)
                if ext in {'.py', '.pyc'}:
                    stdlib_modules.add(name)
    
    return stdlib_modules

class DependencyInfo(BaseModel):
    name: str
    version: Optional[str] = None
    is_standard_lib: bool = False
    is_local: bool = False

    @classmethod
    def from_import(cls, module_name: str, code_root: Path) -> ""DependencyInfo"":
        """"""Create DependencyInfo from a module name""""""
        root_module = module_name.split('.')[0]
        
        # Check if its a standard library module
        if root_module in get_stdlib_modules():
            return cls(
                name=root_module,
                is_standard_lib=True
            )
        
        # Check if its a local module
        local_module_path = code_root / f""{root_module}.py""
        if local_module_path.exists():
            return cls(
                name=root_module,
                is_local=True
            )
        
        # Must be an external dependency
        try:
            dep_version = version(root_module)
            return cls(
                name=root_module,
                version=dep_version
            )
        except PackageNotFoundError:
            return cls(name=root_module)


class ArgumentInfo(BaseModel):
    name: str
    type_annotation: Optional[str] = None
    default_value: Optional[str] = None

class MethodInfo(BaseModel):
    name: str
    code: str
    docstring: Optional[str] = None
    args: List[ArgumentInfo] = Field(default_factory=list)
    return_annotation: Optional[str] = None
    decorators: List[str] = Field(default_factory=list)
    is_property: bool = False
    is_classmethod: bool = False
    is_staticmethod: bool = False

class ClassInfo(BaseModel):
    name: str
    code: str
    docstring: Optional[str] = None
    methods: List[MethodInfo] = Field(default_factory=list)
    base_classes: List[str] = Field(default_factory=list)
    filepath: str
    class_variables: Dict[str, Optional[str]] = Field(default_factory=dict)

    def _is_special_method(self, decorator_list: List[str]) -> tuple:
        """"""Determine if method has special decorators""""""
        is_property = any(d for d in decorator_list if isinstance(d, str) and ""property"" in d)
        is_classmethod = any(d for d in decorator_list if isinstance(d, str) and ""classmethod"" in d)
        is_staticmethod = any(d for d in decorator_list if isinstance(d, str) and ""staticmethod"" in d)
        return is_property, is_classmethod, is_staticmethod

    def _extract_class_info(self, node: ast.ClassDef, content: str, filepath: str) -> ""ClassInfo"":
        """"""Extract information about a class""""""
        methods = []
        class_variables = {}
        
        # Get base classes
        base_classes = [ast.unparse(base) for base in node.bases]
        
        for body_item in node.body:
            if isinstance(body_item, ast.FunctionDef):
                method_code = ast.unparse(body_item)
                decorators = self._extract_decorators(body_item)
                is_property = any(""property"" in d for d in decorators)
                is_classmethod = any(""classmethod"" in d for d in decorators)
                is_staticmethod = any(""staticmethod"" in d for d in decorators)
                
                # Parse arguments
                args = []
                for i, arg in enumerate(body_item.args.args[1:] if not is_staticmethod else body_item.args.args):
                    default = body_item.args.defaults[i] if i < len(body_item.args.defaults) else None
                    args.append(self._parse_argument(arg, default))

                methods.append(MethodInfo(
                    name=body_item.name,
                    code=method_code,
                    docstring=ast.get_docstring(body_item),
                    args=args,
                    return_annotation=ast.unparse(body_item.returns) if body_item.returns else None,
                    decorators=decorators,
                    is_property=is_property,
                    is_classmethod=is_classmethod,
                    is_staticmethod=is_staticmethod
                ))
            elif isinstance(body_item, ast.AnnAssign):
                # Class variable with type annotation
                target_str = ast.unparse(body_item.target)
                value = ast.unparse(body_item.value) if body_item.value else None
                class_variables[target_str] = value
            elif isinstance(body_item, ast.Assign):
                # Class variable without type annotation
                for target in body_item.targets:
                    target_str = ast.unparse(target)
                    value = ast.unparse(body_item.value) if body_item.value else None
                    class_variables[target_str] = value

        return ClassInfo(
            name=node.name,
            code=ast.unparse(node),
            docstring=ast.get_docstring(node),
            methods=methods,
            base_classes=base_classes,
            filepath=filepath,
            class_variables=class_variables
        )

class ImportInfo(BaseModel):
    module_name: str
    imported_names: List[str] = Field(default_factory=list)
    is_from_import: bool = False
    alias: Optional[str] = None


class FunctionInfo(BaseModel):
    code: str
    function_name: str
    filepath: str
    docstring: Optional[str] = None
    args: List[ArgumentInfo] = Field(default_factory=list)
    return_annotation: Optional[str] = None
    decorators: List[str] = Field(default_factory=list)

class FileInfo(BaseModel):
    path: Path
    content: str = """"  # New field to store the full code content
    functions: List[FunctionInfo] = Field(default_factory=list)
    classes: List[ClassInfo] = Field(default_factory=list)
    imports: List[ImportInfo] = Field(default_factory=list)
    dependencies: List[DependencyInfo] = Field(default_factory=list)

class CodeAnalyzer(BaseModel):
    code_root: Path
    def_prefixes: List[str] = Field(default=['def ', 'async def '])
    newline: str = Field(default='\n')
    files: List[FileInfo] = Field(default_factory=list)
    dependency_graph: Optional[nx.DiGraph] = None
    
    class Config:
        arbitrary_types_allowed = True
        
    @classmethod
    def create(cls, code_root: Path) -> ""CodeAnalyzer"":
        """"""Factory method to create a CodeAnalyzer instance""""""
        return cls(
            code_root=code_root,
            files=[],
            dependency_graph=None
        )

    # Remove the __init__ method and use model_validator instead
    @model_validator(mode='after')
    def initialize_graph(self) -> ""CodeAnalyzer"":
        """"""Initialize the dependency graph after model creation""""""
        if self.dependency_graph is None:
            self.dependency_graph = nx.DiGraph()
        return self

    def _parse_argument(self, arg: ast.arg, default=None) -> ArgumentInfo:
        """"""Parse function/method argument information""""""
        return ArgumentInfo(
            name=arg.arg,
            type_annotation=ast.unparse(arg.annotation) if arg.annotation else None,
            default_value=ast.unparse(default) if default else None
        )

    def _extract_decorators(self, node: ast.FunctionDef) -> List[str]:
        """"""Extract decorator information from a function/method node""""""
        return [ast.unparse(decorator) for decorator in node.decorator_list]

    def _is_special_method(self, decorator_list: List[str]) -> tuple:
        """"""Determine if method has special decorators""""""
        is_property = any(property in d for d in decorator_list)
        is_classmethod = any(classmethod in d for d in decorator_list)
        is_staticmethod = any(staticmethod in d for d in decorator_list)
        return is_property, is_classmethod, is_staticmethod

    def _extract_imports(self, node: ast.Module) -> List[ImportInfo]:
        """"""Extract import information from a module""""""
        imports = []
        for node_item in node.body:
            if isinstance(node_item, ast.Import):
                for name in node_item.names:
                    imports.append(ImportInfo(
                        module_name=name.name,
                        alias=name.asname,
                        imported_names=[]
                    ))
            elif isinstance(node_item, ast.ImportFrom):
                if node_item.module:
                    imports.append(ImportInfo(
                        module_name=node_item.module,
                        imported_names=[name.name for name in node_item.names],
                        is_from_import=True,
                        alias=None
                    ))
        return imports

    def _analyze_dependencies(self, imports: List[ImportInfo]) -> List[DependencyInfo]:
        """"""Analyze dependencies from imports""""""
        seen_modules = set()
        dependencies = []
        
        for imp in imports:
            module_name = imp.module_name
            if module_name in seen_modules:
                continue
                
            seen_modules.add(module_name)
            dependencies.append(
                DependencyInfo.from_import(module_name, self.code_root)
            )
        
        return dependencies

    def analyze_file(self, filepath: str) -> FileInfo:
        """"""Analyze a single Python file""""""
        try:
            with open(filepath, 'r', encoding='utf-8') as file:
                content = file.read()
            
            tree = ast.parse(content)
            
            functions = []
            classes = []
            
            # Extract imports first
            imports = self._extract_imports(tree)
            dependencies = self._analyze_dependencies(imports)
            
            def visit_node(node):
                """"""Recursively visit nodes to find all functions and methods""""""
                if isinstance(node, ast.FunctionDef):
                    functions.append(self._extract_function_info(node, filepath))
                elif isinstance(node, ast.ClassDef):
                    classes.append(self._extract_class_info(node, content, filepath))
                    # Also visit class body for nested functions/classes
                    for item in node.body:
                        visit_node(item)
                elif isinstance(node, ast.Module):
                    for item in node.body:
                        visit_node(item)
                # Handle other node types that might contain functions (like If, With, etc.)
                elif hasattr(node, 'body'):
                    if isinstance(node.body, list):
                        for item in node.body:
                            visit_node(item)
                    else:
                        visit_node(node.body)
                if hasattr(node, 'orelse'):
                    if isinstance(node.orelse, list):
                        for item in node.orelse:
                            visit_node(item)
                    elif node.orelse is not None:
                        visit_node(node.orelse)
                if hasattr(node, 'finalbody'):
                    for item in node.finalbody:
                        visit_node(item)

            # Start the recursive visit
            visit_node(tree)
                
            return FileInfo(
                path=Path(filepath),
                content=content,  # Store the full code content here
                functions=functions,
                classes=classes,
                imports=imports,
                dependencies=dependencies
            )
        except Exception as e:
            print(f""Error parsing file {filepath}: {str(e)}"")
            import traceback
            print(traceback.format_exc())
            return FileInfo(path=Path(filepath))
    
    def build_dependency_graph(self):
        """"""Build a dependency graph of the project""""""
        self.dependency_graph = nx.DiGraph()
        
        for file_info in self.files:
            file_node = str(file_info.path)
            self.dependency_graph.add_node(file_node)
            
            for dep in file_info.dependencies:
                if dep.is_local:
                    # Add edge for local dependencies
                    dep_file = str(self.code_root / f""{dep.name}.py"")
                    self.dependency_graph.add_edge(file_node, dep_file)

    def get_class_hierarchy(self) -> nx.DiGraph:
        """"""Build and return the class hierarchy graph""""""
        hierarchy = nx.DiGraph()
        
        for file_info in self.files:
            for class_info in file_info.classes:
                hierarchy.add_node(class_info.name)
                for base in class_info.base_classes:
                    hierarchy.add_edge(base, class_info.name)
                    
        return hierarchy

    def get_dependency_cycles(self) -> List[List[str]]:
        """"""Find circular dependencies in the project""""""
        if not self.dependency_graph:
            self.build_dependency_graph()
        return list(nx.simple_cycles(self.dependency_graph))

    def to_dataframe(self) -> Dict[str, pd.DataFrame]:
        """"""Convert the analyzed data to multiple DataFrames""""""
        try:
            # Functions DataFrame
            functions_data = [
                {
                'filepath': func.filepath,
                'name': func.function_name,
                'docstring': func.docstring,
                'args': [arg.dict() for arg in func.args],
                'return_annotation': func.return_annotation,
                'decorators': func.decorators
                }
                for file in self.files
                for func in file.functions
            ]
        
            # Classes DataFrame
            classes_data = [
                {
                    'filepath': cls.filepath,
                'name': cls.name,
                'docstring': cls.docstring,
                'methods_count': len(cls.methods),
                'base_classes': cls.base_classes,
                'variables_count': len(cls.class_variables),
                'methods': [method.name for method in cls.methods],
                    'has_docstring': cls.docstring is not None
                }
                for file in self.files
                for cls in file.classes
            ]
        
            # Dependencies DataFrame
            dependencies_data = [
                  {
                    'filepath': str(file.path),
                    'dependency': dep.name,
                    'version': dep.version,
                    'is_standard_lib': dep.is_standard_lib,
                    'is_local': dep.is_local
                }
                for file in self.files
                for dep in file.dependencies
            ]

            # Full Code Content DataFrame
            files_data = [
                {
                'filepath': str(file.path),
                    'content': file.content  # Include the full code content here
                }
                for file in self.files
            ]

            return {
                'functions': pd.DataFrame(functions_data) if functions_data else pd.DataFrame(),
                'classes': pd.DataFrame(classes_data) if classes_data else pd.DataFrame(),
                'dependencies': pd.DataFrame(dependencies_data) if dependencies_data else pd.DataFrame(),
                'files': pd.DataFrame(files_data) if files_data else pd.DataFrame()  # New DataFrame for full code content
            }
        except Exception as e:
            print(f""Error creating DataFrames: {str(e)}"")
            return {
                'functions': pd.DataFrame(),
                'classes': pd.DataFrame(),
                'dependencies': pd.DataFrame(),
                'files': pd.DataFrame()  # Ensure an empty DataFrame is returned on error
            }
    def _extract_function_info(self, node: ast.FunctionDef, filepath: str) -> FunctionInfo:
        """"""Extract information about a function""""""
        args = []
        for i, arg in enumerate(node.args.args):
            default = node.args.defaults[i] if i < len(node.args.defaults) else None
            args.append(self._parse_argument(arg, default))

        return FunctionInfo(
            code=ast.unparse(node),
            function_name=node.name,
            filepath=filepath,
            docstring=ast.get_docstring(node),
            args=args,
            return_annotation=ast.unparse(node.returns) if node.returns else None,
            decorators=self._extract_decorators(node)
        )

    # def to_dataframe(self) -> pd.DataFrame:
    #     """"""
    #     Convert the analyzed data to a pandas DataFrame
    #     """"""
    #     rows = []
    #     for file in self.files:
    #         for func in file.functions:
    #             rows.append({
    #                 filepath: func.filepath,
    #                 function_name: func.function_name,
    #                 code: func.code,
    #                 docstring: func.docstring,
    #                 args: func.args,
    #                 return_annotation: func.return_annotation
    #             })
    #     return pd.DataFrame(rows)
    def analyze_repo(self) -> List[FileInfo]:
        """"""
        Analyze all Python files in the repository.
        Returns a list of FileInfo objects containing analysis results.
        """"""
        def should_skip_path(path: Path) -> bool:
            """"""Helper to determine if a path should be skipped""""""
            parts = path.parts
            return any(
                part.startswith('.') or 
                part == '.venv' or 
                part == 'venv' or
                part == '__pycache__' or
                part == 'build' or
                part == 'dist'
                for part in parts
            )

        code_files = [
            f for f in self.code_root.glob(""**/*.py"")
            if not should_skip_path(f.relative_to(self.code_root))
        ]

        num_files = len(code_files)
        print(f""Total number of .py files: {num_files}"")

        if num_files == 0:
            print(""Verify the repository exists and code_root is set correctly."")
            return []

        self.files = []
        total_functions = 0
        total_methods = 0
        total_classes = 0
        
        for code_file in code_files:
            try:
                file_info = self.analyze_file(str(code_file))
                self.files.append(file_info)
                
                # Count functions and methods separately
                total_functions += len(file_info.functions)
                for class_info in file_info.classes:
                    total_methods += len(class_info.methods)
                    total_classes += 1
                    
                rr(f""[green]Analyzed: {code_file}[/green]"")
                rr(f""  Functions: {len(file_info.functions)}"")
                rr(f""  Classes: {len(file_info.classes)}"")
                for class_info in file_info.classes:
                    rr(f""    Class {class_info.name}: {len(class_info.methods)} methods"")
                    
            except Exception as e:
                rr(f""[red]Error analyzing {code_file}: {str(e)}[/red]"")
                import traceback
                rr(f""[red]{traceback.format_exc()}[/red]"")

        # Print summary statistics
        successful = len([f for f in self.files if f.functions or f.classes])
        failed = num_files - successful
        
        print(f""\nAnalysis complete:"")
        print(f""Files processed successfully: {successful}"")
        print(f""Files failed: {failed}"")
        print(f""Total classes found: {total_classes}"")
        print(f""Total standalone functions found: {total_functions}"")
        print(f""Total methods found: {total_methods}"")
        print(f""Total functions + methods: {total_functions + total_methods}"")

        return self.files
    def _extract_function_info(self, node: ast.FunctionDef, filepath: str) -> FunctionInfo:
        """"""Extract information about a function""""""
        args = []
        for i, arg in enumerate(node.args.args):
            default = node.args.defaults[i] if i < len(node.args.defaults) else None
            args.append(self._parse_argument(arg, default))

        return FunctionInfo(
            code=ast.unparse(node),
            function_name=node.name,
            filepath=filepath,
            docstring=ast.get_docstring(node),
            args=args,
            return_annotation=ast.unparse(node.returns) if node.returns else None,
            decorators=self._extract_decorators(node)
        )

    def _extract_class_info(self, node: ast.ClassDef, content: str, filepath: str) -> ClassInfo:
        """"""Extract information about a class""""""
        methods = []
        class_variables = {}
        
        # Get base classes
        base_classes = [ast.unparse(base) for base in node.bases]
        
        for body_item in node.body:
            if isinstance(body_item, ast.FunctionDef):
                method_code = ast.unparse(body_item)
                decorators = self._extract_decorators(body_item)
                is_property = any(""property"" in d for d in decorators)
                is_classmethod = any(""classmethod"" in d for d in decorators)
                is_staticmethod = any(""staticmethod"" in d for d in decorators)
                
                # Parse arguments
                args = []
                for i, arg in enumerate(body_item.args.args[1:] if not is_staticmethod else body_item.args.args):
                    default = body_item.args.defaults[i] if i < len(body_item.args.defaults) else None
                    args.append(self._parse_argument(arg, default))

                methods.append(MethodInfo(
                    name=body_item.name,
                    code=method_code,
                    docstring=ast.get_docstring(body_item),
                    args=args,
                    return_annotation=ast.unparse(body_item.returns) if body_item.returns else None,
                    decorators=decorators,
                    is_property=is_property,
                    is_classmethod=is_classmethod,
                    is_staticmethod=is_staticmethod
                ))
            elif isinstance(body_item, ast.AnnAssign):
                # Class variable with type annotation
                target_str = ast.unparse(body_item.target)
                value = ast.unparse(body_item.value) if body_item.value else None
                class_variables[target_str] = str(value) if value is not None else None
            elif isinstance(body_item, ast.Assign):
                # Class variable without type annotation
                for target in body_item.targets:
                    target_str = ast.unparse(target)
                    value = ast.unparse(body_item.value) if body_item.value else None
                    class_variables[target_str] = str(value) if value is not None else None

        return ClassInfo(
            name=node.name,
            code=ast.unparse(node),
            docstring=ast.get_docstring(node),
            methods=methods,
            base_classes=base_classes,
            filepath=filepath,
            class_variables=class_variables
        )
def main():
    analyzer = CodeAnalyzer.create(code_root=Path(""c:/mygit/compuse/computer_use_demo""))
    analyzer.analyze_repo()
    df = analyzer.to_dataframe()
    df['functions'].to_csv(""functions1.csv"", index=False)
    df['classes'].to_csv(""classes1.csv"", index=False)
    df['dependencies'].to_csv(""dependencies1.csv"", index=False)
    df['files'].to_csv(""files1.csv"", index=False)
if __name__ == ""__main__"":
    main()


"
c:\mygit\compuse\computer_use_demo\tools\collection.py,"## collection.py
""""""Collection classes for managing multiple tools.""""""

from typing import Any
import json
from anthropic.types.beta import BetaToolUnionParam
from icecream import ic
from .base import (
    BaseAnthropicTool,
    ToolError,
    ToolFailure,
    ToolResult,
)
ICECREAM_OUTPUT_FILE = ""debug_log.json""

def write_to_file(s, file_path=ICECREAM_OUTPUT_FILE):
    """"""
    Write debug output to a file, formatting JSON content in a pretty way.
    """"""
    lines = s.split('\n')
    formatted_lines = []
    
    for line in lines:
        if ""tool_input:"" in line:
            try:
                # Extract JSON part from the line
                json_part = line.split(""tool_input: "")[1]
                # Parse and pretty-print the JSON
                json_obj = json.loads(json_part)
                pretty_json = json.dumps(json_obj, indent=4)
                formatted_lines.append(""tool_input: "" + pretty_json)
            except (IndexError, json.JSONDecodeError):
                # If parsing fails, just append the original line
                formatted_lines.append(line)
        else:
            formatted_lines.append(line)
    
    # Write to file
    with open(file_path, 'a', encoding=""utf-8"") as f:
        f.write('\n'.join(formatted_lines))
        f.write('\n' + '-' * 80 + '\n')  # Add separator between entries

class ToolCollection:
    """"""A collection of anthropic-defined tools.""""""

    def __init__(self, *tools: BaseAnthropicTool):
        self.tools = tools
        ic(self.tools)
        self.tool_map = {tool.to_params()[""name""]: tool for tool in tools}
        ic(self.tool_map)
    def to_params(
        self,
    ) -> list[BetaToolUnionParam]:
        ic()
        params = [tool.to_params() for tool in self.tools]
        if params:
            params[-1][""cache_control""] = {""type"": ""ephemeral""}
        return params

    async def run(self, *, name: str, tool_input: dict[str, Any]) -> ToolResult:
        ic.configureOutput(includeContext=True, outputFunction=write_to_file)

        tool = self.tool_map.get(name)
    
        if not tool:
            return ToolFailure(error=f""Tool {name} is invalid"")
        try:
            ic(tool_input)
            return await tool(**tool_input)
        except ToolError as e:
            return ToolFailure(error=e.message)
#""C:/repo/code_test/code_context_manager.py"""
c:\mygit\compuse\computer_use_demo\tools\computer.py,"import asyncio
import base64
import os
import shlex
import shutil
from enum import StrEnum
from typing import Optional, Union, Tuple, Literal, TypedDict
from pathlib import Path
from uuid import uuid4
import pyautogui
import logging
import time
import pygetwindow as gw
from PIL import Image
from anthropic.types.beta import BetaToolComputerUse20241022Param
import pyperclip
from .base import BaseAnthropicTool, CLIResult, ToolError, ToolResult
from .run import run

OUTPUT_DIR = os.path.join(os.getenv('APPDATA', ''), 'computer_tool', 'outputs')

TYPING_DELAY_MS = 12
TYPING_GROUP_SIZE = 50

Action = Literal[
    ""key"",
    ""type"",
    ""mouse_move"",
    ""left_click"",
    ""left_click_drag"",
    ""right_click"",
    ""middle_click"",
    ""double_click"",
    ""screenshot"",
    ""cursor_position"",
    # ""speak"",  # Add speak action
    ""open_url"", # Add open_url action
    ""get_window_title"", # Add get_window_title
]

class Resolution(TypedDict):
    width: int
    height: int


# sizes above XGA/WXGA are not recommended (see README.md)
# scale down to one of these targets if ComputerTool._scaling_enabled is set
MAX_SCALING_TARGETS: dict[str, Resolution] = {
    ""XGA"": Resolution(width=1024, height=768),  # 4:3
    ""WXGA"": Resolution(width=1280, height=800),  # 16:10
    ""FWXGA"": Resolution(width=1366, height=768),  # ~16:9
}


class ScalingSource(StrEnum):
    COMPUTER = ""computer""
    API = ""api""

class ComputerToolOptions(TypedDict):
    display_height_px: int
    display_width_px: int
    display_number: Optional[int]

class ComputerTool(BaseAnthropicTool):
    description=""""""
    A cross-platform tool that allows the agent to interact with the screen, keyboard, and mouse.
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    name: Literal[""computer""] = ""computer""
    api_type: Literal[""computer_20241022""] = ""computer_20241022""
    width: int
    height: int
    display_num: int | None

    _screenshot_delay = 1.0
    _scaling_enabled = True

    @property
    def options(self) -> ComputerToolOptions:
        width, height = self.scale_coordinates(
            ScalingSource.COMPUTER, self.width, self.height
        )
        return {
            ""display_width_px"": self.width,
            ""display_height_px"": self.height,
            ""display_number"": self.display_num,
        }

    def to_params(self) -> BetaToolComputerUse20241022Param:
        return {""name"": self.name, ""type"": self.api_type, **self.options}

    def __init__(self):
        super().__init__()
        self.width = pyautogui.size().width
        self.height = pyautogui.size().height
        self.display_num = None
        
        os.makedirs(OUTPUT_DIR, exist_ok=True)

    async def __call__(
        self,
        *,
        action: Action,
        text: Optional[str] = None,
        coordinate: Optional[tuple[int, int]] = None,
        **kwargs,
    ) -> ToolResult:
        try:
            if action in (""mouse_move"", ""left_click_drag""):
                if coordinate is None:
                    raise ToolError(f""coordinate is required for {action}"")
                if text is not None:
                    raise ToolError(f""text is not accepted for {action}"")
                if not isinstance(coordinate, (list, tuple)) or len(coordinate) != 2:
                    raise ToolError(f""{coordinate} must be a tuple of length 2"")
                if not all(isinstance(i, int) and i >= 0 for i in coordinate):
                    raise ToolError(f""{coordinate} must be a tuple of non-negative ints"")

                x, y = self.scale_coordinates(
                    ScalingSource.API, coordinate[0], coordinate[1]
                )

                if action == ""mouse_move"":
                    pyautogui.moveTo(x, y)
                    return ToolResult(output=f""Moved mouse to {x}, {y}"")
                else:  # left_click_drag
                    pyautogui.dragTo(x, y, button='left')
                    return ToolResult(output=f""Dragged mouse to {x}, {y}"")

            if action in (""key"", ""type""):
                if text is None:
                    raise ToolError(f""text is required for {action}"")
                if coordinate is not None:
                    raise ToolError(f""coordinate is not accepted for {action}"")
                if not isinstance(text, str):
                    raise ToolError(f""{text} must be a string"")

                if action == ""key"":
                    pyautogui.press(text)
                    return ToolResult(output=f""Pressed key: {text}"")
                else:  # type
                    pyautogui.write(text, interval=TYPING_DELAY_MS/1000)
                    screenshot = await self.screenshot()
                    return ToolResult(
                        output=f""Typed text: {text}"",
                        base64_image=screenshot.base64_image
                    )

            if action in (
                ""left_click"",
                ""right_click"",
                ""double_click"",
                ""middle_click"",
                ""screenshot"",
                ""cursor_position"",
            ):
                if text is not None:
                    raise ToolError(f""text is not accepted for {action}"")
                if coordinate is not None:
                    raise ToolError(f""coordinate is not accepted for {action}"")

                if action == ""screenshot"":
                    return await self.screenshot()

                elif action == ""cursor_position"":
                    pos = pyautogui.position()
                    x, y = self.scale_coordinates(
                        ScalingSource.COMPUTER, pos.x, pos.y
                    )
                    return ToolResult(output=f""X={x},Y={y}"")
                else:
                    click_map = {
                        ""left_click"": lambda: pyautogui.click(button='left'),
                        ""right_click"": lambda: pyautogui.click(button='right'),
                        ""middle_click"": lambda: pyautogui.click(button='middle'),
                        ""double_click"": lambda: pyautogui.doubleClick(),
                    }
                    click_map[action]()
                    return ToolResult(output=f""Performed {action}"")

            raise ToolError(f""Invalid action: {action}"")

        except Exception as e:
            return ToolResult(error=str(e))

    async def screenshot(self) -> ToolResult:
        """"""Take a screenshot of the current screen and return the base64 encoded image.""""""
        try:
            path = Path(OUTPUT_DIR) / f""screenshot_{uuid4().hex}.png""
            
            # Take screenshot
            screen = pyautogui.screenshot()
            
            # Scale if enabled
            if self._scaling_enabled:
                x, y = self.scale_coordinates(
                    ScalingSource.COMPUTER, self.width, self.height
                )
                screen = screen.resize((x, y), Image.Resampling.LANCZOS)
            
            # Save and encode
            screen.save(str(path))
            base64_image = base64.b64encode(path.read_bytes()).decode()
            
            # Clean up old files
            self._cleanup_screenshots()
            
            return ToolResult(
                output=""Screenshot taken"",
                base64_image=base64_image
            )
        except Exception as e:
            return ToolResult(error=f""Failed to take screenshot: {str(e)}"")

    def _cleanup_screenshots(self, max_files: int = 100):
        """"""Clean up old screenshots, keeping only the most recent ones.""""""
        try:
            screenshots = sorted(
                Path(OUTPUT_DIR).glob(""*.png""),
                key=lambda x: x.stat().st_mtime
            )
            if len(screenshots) > max_files:
                for screenshot in screenshots[:-max_files]:
                    screenshot.unlink()
        except Exception as e:
            logging.warning(f""Error cleaning up screenshots: {e}"")

    def scale_coordinates(self, source: ScalingSource, x: int, y: int):
        """"""Scale coordinates to a target maximum resolution.""""""
        if not self._scaling_enabled:
            return x, y
        ratio = self.width / self.height
        target_dimension = None
        for dimension in MAX_SCALING_TARGETS.values():
            # allow some error in the aspect ratio - not ratios are exactly 16:9
            if abs(dimension[""width""] / dimension[""height""] - ratio) < 0.02:
                if dimension[""width""] < self.width:
                    target_dimension = dimension
                break
        if target_dimension is None:
            return x, y
        # should be less than 1
        x_scaling_factor = target_dimension[""width""] / self.width
        y_scaling_factor = target_dimension[""height""] / self.height
        if source == ScalingSource.API:
            if x > self.width or y > self.height:
                raise ToolError(f""Coordinates {x}, {y} are out of bounds"")
            # scale up
            return round(x / x_scaling_factor), round(y / y_scaling_factor)
        # scale down
        return round(x * x_scaling_factor), round(y * y_scaling_factor)
"
c:\mygit\compuse\computer_use_demo\tools\edit.py,"## edit.py
import os
import re
from pathlib import Path
from collections import defaultdict
from typing import Literal, get_args
from anthropic.types.beta import BetaToolTextEditor20241022Param
from .base import BaseAnthropicTool, ToolError, ToolResult
from .run import maybe_truncate
from typing import List, Optional
from icecream import ic
import sys
from rich import print as rr
# Reconfigure stdout to use UTF-8 encoding
sys.stdout.reconfigure(encoding='utf-8')
# include the context for the icecream debugger
ic.configureOutput(includeContext=True)

# Reconfigure stdout to use UTF-8 encoding
Command = Literal[
    ""view"",
    ""create"",
    ""str_replace"",
    ""insert"",
    ""undo_edit"",
]
SNIPPET_LINES: int = 4

class EditTool(BaseAnthropicTool):
    description=""""""
    A cross-platform filesystem editor tool that allows the agent to view, create, and edit files.
    The tool parameters are defined by Anthropic and are not editable.
    """"""

    api_type: Literal[""text_editor_20241022""] = ""text_editor_20241022""
    name: Literal[""str_replace_editor""] = ""str_replace_editor""

    _file_history: dict[Path, list[str]]

    def __init__(self):
        self._file_history = defaultdict(list)
        super().__init__()

    def to_params(self) -> BetaToolTextEditor20241022Param:
        return {
            ""name"": self.name,
            ""type"": self.api_type,
        }

    async def __call__(
        self,
        *,
        command: Command,
        path: str,
        file_text: str | None = None,
        view_range: list[int] | None = None,
        old_str: str | None = None,
        new_str: str | None = None,
        insert_line: int | None = None,
        **kwargs,
    ) -> ToolResult:

        _path = Path(path).resolve()  # resolve() handles both Windows and Unix paths
        ic(_path)

        # _path = self.validate_path(command, _path)
        if command == ""view"":
            return await self.view(_path, view_range)
        elif command == ""create"":
            if not file_text:
                raise ToolError(""Parameter `file_text` is required for command: create"")
            self.write_file(_path, file_text)
            self._file_history[_path].append(file_text)
            return ToolResult(output=f""File created successfully at: {_path}"")
        elif command == ""str_replace"":
            if not old_str:
                raise ToolError(""Parameter `old_str` is required for command: str_replace"")
            return self.str_replace(_path, old_str, new_str)
        elif command == ""insert"":
            if insert_line is None:
                raise ToolError(""Parameter `insert_line` is required for command: insert"")
            if not new_str:
                raise ToolError(""Parameter `new_str` is required for command: insert"")
            return self.insert(_path, insert_line, new_str)
        elif command == ""undo_edit"":
            return self.undo_edit(_path)
        raise ToolError(
            f'Unrecognized command {command}. The allowed commands for the {self.name} tool are: {"", "".join(get_args(Command))}'
        )
    def normalize_path(self, path: Optional[str]) -> Path:
        """"""
        Normalize a file path to ensure it starts with 'C:/repo/'.
        
        Args:
            path: Input path string that needs to be normalized
            Note:
            This method is used to normalize the path provided by the user.
            The normalized path is used to ensure that the path starts with 'C:/repo/'
            and is a valid path.
        Returns:
            Normalized path string starting with 'C:/repo/'
            
        Raises:
            ValueError: If the path is None or empty
        """"""
        if not path:
            raise ValueError('Path cannot be empty')
        
        # Convert to string in case we receive a Path object
        normalized_path = str(path)
        
        # Convert all backslashes to forward slashes
        normalized_path = normalized_path.replace('\\', '/')
        
        # Remove any leading/trailing whitespace
        normalized_path = normalized_path.strip()
        
        # Remove multiple consecutive forward slashes
        normalized_path = re.sub(r'/+', '/', normalized_path)
        
        # Remove 'C:' or 'c:' if it exists at the start
        normalized_path = re.sub(r'^[cC]:', '', normalized_path)
        
        # Remove '/repo/' if it exists at the start
        normalized_path = re.sub(r'^/repo/', '', normalized_path)
        
        # Remove leading slash if it exists
        normalized_path = re.sub(r'^/', '', normalized_path)
        
        # Combine with base path
        return Path(f'C:/repo/{normalized_path}')

    def validate_path(self, command: str, path: Path):
        """"""
        Check that the path/command combination is valid in a cross-platform manner.
        param command: The command that the user is trying to run.
        """"""
        path = self.normalize_path(path)
        try:
            # This handles both Windows and Unix paths correctly
            path = path.resolve()
        except Exception as e:
            raise ToolError(f""Invalid path format: {path}. Error: {str(e)}"")

        # Check if it's an absolute path
        if not path.is_absolute():
            suggested_path = Path.cwd() / path
            raise ToolError(
                f""The path {path} is not an absolute path. Maybe you meant {suggested_path}?""
            )

        # Check if path exists
        if not path.exists() and command != ""create"":
            raise ToolError(
                f""The path {path} does not exist. Please provide a valid path.""
            )
        if path.exists() and command == ""create"":
            raise ToolError(
                f""File already exists at: {path}. Cannot overwrite files using command `create`.""
            )

        # Check if the path points to a directory
        if path.is_dir():
            if command != ""view"":
                raise ToolError(
                    f""The path {path} is a directory and only the `view` command can be used on directories""
                )
    async def view(self, path: Path, view_range: Optional[List[int]] = None) -> ToolResult:
        """"""Implement the view command using cross-platform methods.""""""
        ic(path)
        path = self.normalize_path(path)
        if path.is_dir():
            if view_range:
                raise ToolError(
                    ""The `view_range` parameter is not allowed when `path` points to a directory.""
                )

            try:
                # Cross-platform directory listing using pathlib
                files = []
                for level in range(3):  # 0-2 levels deep
                    if level == 0:
                        pattern = ""*""
                    else:
                        pattern = os.path.join(*[""*""] * (level + 1))

                    for item in path.glob(pattern):
                        # Skip hidden files and directories
                        if not any(part.startswith('.') for part in item.parts):
                            files.append(str(item.resolve()))  # Ensure absolute paths

                stdout = ""\n"".join(sorted(files))
                stdout = f""Here's the files and directories up to 2 levels deep in {path}, excluding hidden items:\n{stdout}\n""
                return ToolResult(output=stdout, error=None, base64_image=None)
            except Exception as e:
                return ToolResult(output="""", error=str(e), base64_image=None)

        # If it's a file, read its content
        file_content = self.read_file(path)
        init_line = 1
        if view_range:
            if len(view_range) != 2 or not all(isinstance(i, int) for i in view_range):
                raise ToolError(""Invalid `view_range`. It should be a list of two integers."")
            file_lines = file_content.split(""\n"")
            n_lines_file = len(file_lines)
            init_line, final_line = view_range
            if init_line < 1 or init_line > n_lines_file:
                raise ToolError(
                    f""Invalid `view_range`: {view_range}. Its first element `{init_line}` should be within the range of lines of the file: {[1, n_lines_file]}""
                )
            if final_line > n_lines_file:
                raise ToolError(
                    f""Invalid `view_range`: {view_range}. Its second element `{final_line}` should be smaller than the number of lines in the file: `{n_lines_file}`""
                )
            if final_line != -1 and final_line < init_line:
                raise ToolError(
                    f""Invalid `view_range`: {view_range}. Its second element `{final_line}` should be larger or equal than its first `{init_line}`""
                )

            if final_line == -1:
                file_content = ""\n"".join(file_lines[init_line - 1:])
            else:
                file_content = ""\n"".join(file_lines[init_line - 1 : final_line])
        ic(file_content)
        return ToolResult(output=self._make_output(file_content, str(path), init_line=init_line), error=None, base64_image=None)
    def str_replace(self, path: Path, old_str: str, new_str: Optional[str]) -> ToolResult:
        """"""Implement the str_replace command, which replaces old_str with new_str in the file content.""""""
        try:
            # Read the file content
            ic(path)
            path = self.normalize_path(path)
            file_content = self.read_file(path).expandtabs()
            old_str = old_str.expandtabs()
            new_str = new_str.expandtabs() if new_str is not None else """"

            # Check if old_str is unique in the file
            occurrences = file_content.count(old_str)
            if occurrences == 0:
                raise ToolError(f""No replacement was performed, old_str `{old_str}` did not appear verbatim in {path}."")
            elif occurrences > 1:
                file_content_lines = file_content.split(""\n"")
                lines = [
                    idx + 1
                    for idx, line in enumerate(file_content_lines)
                    if old_str in line
                ]
                raise ToolError(
                    f""No replacement was performed. Multiple occurrences of old_str `{old_str}` in lines {lines}. Please ensure it is unique""
                )

            # Replace old_str with new_str
            new_file_content = file_content.replace(old_str, new_str)

            # Write the new content to the file
            self.write_file(path, new_file_content)

            # Save the content to history
            self._file_history[path].append(file_content)

            # Create a snippet of the edited section
            replacement_line = file_content.split(old_str)[0].count(""\n"")
            start_line = max(0, replacement_line - SNIPPET_LINES)
            end_line = replacement_line + SNIPPET_LINES + new_str.count(""\n"")
            snippet = ""\n"".join(new_file_content.split(""\n"")[start_line : end_line + 1])

            # Prepare the success message
            success_msg = f""The file {path} has been edited. ""
            success_msg += self._make_output(snippet, f""a snippet of {path}"", start_line + 1)
            success_msg += ""Review the changes and make sure they are as expected. Edit the file again if necessary.""

            return ToolResult(output=success_msg, error=None, base64_image=None)

        except Exception as e:
            return ToolResult(output=None, error=str(e), base64_image=None)
    def insert(self, path: Path, insert_line: int, new_str: str) -> ToolResult:
        """"""Implement the insert command, which inserts new_str at the specified line in the file content.""""""
        path = self.normalize_path(path)
        file_text = self.read_file(path).expandtabs()
        new_str = new_str.expandtabs()
        file_text_lines = file_text.split(""\n"")
        n_lines_file = len(file_text_lines)

        if insert_line < 0 or insert_line > n_lines_file:
            raise ToolError(
                f""Invalid `insert_line` parameter: {insert_line}. It should be within the range of lines of the file: {[0, n_lines_file]}""
            )

        new_str_lines = new_str.split(""\n"")
        new_file_text_lines = (
            file_text_lines[:insert_line]
            + new_str_lines
            + file_text_lines[insert_line:]
        )
        snippet_lines = (
            file_text_lines[max(0, insert_line - SNIPPET_LINES) : insert_line]
            + new_str_lines
            + file_text_lines[insert_line : insert_line + SNIPPET_LINES]
        )

        new_file_text = ""\n"".join(new_file_text_lines)
        snippet = ""\n"".join(snippet_lines)

        self.write_file(path, new_file_text)
        self._file_history[path].append(file_text)

        success_msg = f""The file {path} has been edited. ""
        success_msg += self._make_output(
            snippet,
            ""a snippet of the edited file"",
            max(1, insert_line - SNIPPET_LINES + 1),
        )
        success_msg += ""Review the changes and make sure they are as expected (correct indentation, no duplicate lines, etc). Edit the file again if necessary.""
        return ToolResult(output=success_msg)
    def ensure_valid_repo_path(filename: str) -> str:
        ### Need to Try this out ###
        base_path = ""C:/repo/""
        
        # Normalize path separators for cross-platform compatibility
        filename = filename.replace(""\\"", ""/"")
        
        # Check if the filename already starts with the base path
        if not filename.startswith(base_path):
            # Prepend the base path if it's not present
            filename = os.path.join(base_path, filename.lstrip(""/""))
        filename = self.normalize_path(filename)
        # Return the standardized path using Windows-style separator
        return os.path.normpath(filename)
    def undo_edit(self, path: Path) -> ToolResult:
        """"""Implement the undo_edit command.""""""
        path = self.normalize_path(path)
        if not self._file_history[path]:
            raise ToolError(f""No edit history found for {path}."")

        old_text = self._file_history[path].pop()
        self.write_file(path, old_text)

        return ToolResult(
            output=f""Last edit to {path} undone successfully. {self._make_output(old_text, str(path))}""
        )

    def read_file(self, path: Path) -> str:
        rr(path)

        path = self.normalize_path(path)

        try:
            return path.read_text(encoding=""utf-8"").encode('ascii', errors='replace').decode('ascii')
        except Exception as e:
            ic(f""Error reading file {path}: {e}"")
            raise ToolError(f""Ran into {e} while trying to read {path}"") from None
    def write_file(self, path: Path, file: str):
        path = self.normalize_path(path)
        """"""Write the content of a file to a given path; raise a ToolError if an error occurs.""""""
        try:
            path.write_text(file, encoding=""utf-8"")
        except Exception as e:
            raise ToolError(f""Ran into {e} while trying to write to {path}"") from None

    def _make_output(
        self,
        file_content: str,
        file_descriptor: str,
        init_line: int = 1,
        expand_tabs: bool = True,
    ) -> str:
        """"""Generate output for the CLI based on the content of a file.""""""
        file_content = maybe_truncate(file_content)
        if expand_tabs:
            file_content = file_content.expandtabs()
        file_content = ""\n"".join(
            [
                f""{i + init_line:6}\t{line}""
                for i, line in enumerate(file_content.split(""\n""))
            ]
        )
        return (
            f""Here's the result of running ` -n` on {file_descriptor}:\n""
            + file_content
            + ""\n""
        )
"
c:\mygit\compuse\computer_use_demo\tools\example_tool.py,"from .base import BaseAnthropicTool

class ExampleTool(BaseAnthropicTool):
    @property
    def name(self) -> str:
        return ""example_tool""

    @property
    def description(self) -> str:
        return ""An example tool that does something.""

    def __init__(self):
        super().__init__(input_schema={
            ""type"": ""object"",
            ""properties"": {
                ""example_param"": {
                    ""type"": ""string"",
                    ""description"": ""An example parameter for the tool.""
                }
            },
            ""required"": [""example_param""]
        })

    def __call__(self, **kwargs) -> str:
        # Implement the tool's functionality here
        return f""Example tool executed with {kwargs.get('example_param')}"" "
c:\mygit\compuse\computer_use_demo\tools\expert.py,"#expert.py
from openai import OpenAI
# load the API key from the environment
from dotenv import load_dotenv
from icecream import ic
from typing import Optional, Literal
from .base import ToolError, ToolResult, BaseAnthropicTool, ToolFailure
load_dotenv()
from rich import print as rr


class GetExpertOpinionTool(BaseAnthropicTool):
    """"""
    A tool takes a detailed description of the problem and everything that has been tried so far, and returns an expert opinion on the problem.
    """"""

    name: Literal[""Opinion""] = ""opinion""
    api_type: Literal[""custom""] = ""custom""
    description: str = ""A tool takes a detailed description of the problem and everything that has been tried so far, and returns an expert opinion on the problem.""



    def to_params(self) -> dict:
        return {
            ""name"": self.name,
            ""description"": self.description,
            ""type"": self.api_type,
            ""input_schema"": {
                ""type"": ""object"",
                ""properties"": {
                    ""command"": {
                        ""type"": ""string"",
                        ""enum"": [""get_opinion""],
                        ""description"": ""The command to get an expert opinion.""
                    },
                    ""problem_description"": {
                        ""type"": ""string"",
                        ""description"": ""A detailed description of the problem and everything that has been tried so far. If for programming, include the code that has been tried.""
                    }
                },
                ""required"": [""command"", ""problem_description""]
            }
        }
        
    async def __call__(     
        self,
        *,
        command: Literal[""get_opinion""],
        problem_description: Optional[str] = None,
        **kwargs,
    ) -> ToolResult:
        """"""
        Executes the specified command.
        """"""
       
        if command == ""get_opinion"":
            ic()
            return await self.get_opinion(problem_description=problem_description)
        if command == ""get_plan"":
            ic()
            return await self.get_plan(problem_description=problem_description)
        else:
            ic()
            raise ToolError(
                f""Unrecognized command '{command}'. Allowed commands: 'list_reports', 'run_report'.""
            )

    async def get_plan(self, problem_description) -> ToolResult:
        prompt = f""""""
        Objective:
You are a Task Decomposition Specialist. Your goal is to meticulously break down any given computer-based task into the smallest reasonable steps. Each step should be clear, actionable, and independently verifiable for completion by someone without prior knowledge of the task or access to the execution environment.
Instructions:
For each step (and sub-step, if necessary), provide the following:
Step [Number]:
Action: A detailed and specific description of the action to be performed.
Expected Result: A description of what should occur or be produced after the action is completed.
Verification Method: A precise method to confirm that the step has been completed, which should:
Be executable by someone who has not seen the previous steps.
Not require access to the environment where the task was performed.
Focus on confirming the completion of the action, not the accuracy of the result (unless completion inherently requires accuracy).
Guidelines:
Clarity and Specificity:
Use clear, unambiguous language.
Include specific details such as file names, URLs, commands, or search queries where applicable.
Step Structure:
Main Steps: Numbered sequentially (e.g., Step 1, Step 2, Step 3).
Sub-Steps: If a step requires multiple actions, break it down into sub-steps (e.g., Sub-Step 1.1, Sub-Step 1.2).
Formatting Requirements:
Use bold headings for Action, Expected Result, and Verification Method for clarity.
Present information in a structured and organized manner.
Independent Verification:
Ensure each verification method can be performed independently of other steps.
Verification should rely only on the outputs or artifacts produced by that specific step.
Verification Methods:
Should be objective, measurable, and specific.
May include:
Checking the existence or properties of a file or document.
Viewing metadata, timestamps, or file contents.
Confirming the presence of specific data, entries, or outputs.
Reviewing screenshots or exported logs.
No Assumptions:
Do not assume the verifier has any prior knowledge of the task or access to previous results.
Do not require the verifier to access the execution environment or external systems beyond what is produced in the step.
Example Format:
Step 1:
Action: Create a new folder named Elevator_Project on your desktop.
Expected Result: A folder named Elevator_Project exists on the desktop.
Verification Method: Check the desktop for the presence of the Elevator_Project folder.
Sub-Step 1.1:
Action: Inside the Elevator_Project folder, create an Excel file named elevator_data.xlsx with two sheets labeled Company_Info and Models.
Expected Result: An Excel file elevator_data.xlsx with two sheets named Company_Info and Models exists in the Elevator_Project folder.
Verification Method: Open elevator_data.xlsx and confirm the sheets Company_Info and Models are present.
Sub-Step 1.2:
Action: In the Company_Info sheet, add column headers in the first row: Manufacturer, Public/Private, Number of Employees, Years in Business.
Expected Result: The Company_Info sheet has the specified headers correctly labeled in the first row.
Verification Method: Open the Company_Info sheet and verify the headers are present and correctly labeled.
Your Task:
{problem_description}
Apply the above guidelines and format to break down the provided task:
Instructions for Completion:
Identify Main Steps:
Start by outlining the major components required to complete the task.
Decompose into Sub-Steps:
Break down each main step into smaller, actionable sub-steps as necessary.
Detail Each Step:
For every step and sub-step, provide the Action, Expected Result, and Verification Method as per the guidelines.
Ensure Independent Verification:
Make sure that each verification method allows someone to confirm completion without prior knowledge or access to the execution environment.
Maintain Clarity and Organization:
Use the specified formatting for consistency and ease of understanding.
Begin your detailed task breakdown below:
        """"""
        return ToolResult(output=prompt)

    async def get_opinion(self, problem_description) -> ToolResult:
        """"""
        Lists all available reports.
        """"""
        try:
            ic()
            client = OpenAI()
            ic(client)
            prompt = f""""""
           The user would like your expert opinion on the following problem:
           {problem_description}
            """"""
            rr(problem_description)
            response = client.chat.completions.create(
                model=""o1-preview"",
                messages=[
                    {
                        ""role"": ""user"",
                        ""content"": [
                            {
                                ""type"": ""text"",
                                ""text"": prompt
                            },
                        ],
                    }
                ]
            )
            ic(response)
            ex_opinion = response.choices[0].message.content
            return ToolResult(output=ex_opinion)
        except Exception as e:
            ic(e)
            rr(f""{str(e).encode('ascii', errors='replace').decode('ascii')}"")
            return ToolFailure(error=""Failed to generate opinion."")







"
c:\mygit\compuse\computer_use_demo\tools\gotourl_reports.py,"import difflib
import pandas as pd
from typing import Optional, Literal, TypedDict
# from tools import ToolResult, , BaseAnthropicTool  # Adjust the import path as necessary
from enum import StrEnum
from .base import ToolError, ToolResult, BaseAnthropicTool
from icecream import ic
from playwright.async_api import async_playwright
import os
class Resolution(TypedDict):
    width: int
    height: int
from rich import print as rr

class ScalingSource(StrEnum):
    COMPUTER = ""computer""
    API = ""api""

class Options(TypedDict):
    display_height_px: int
    display_width_px: int
    display_number: Optional[int]

class GoToURLReportsTool(BaseAnthropicTool):
    """"""
    A tool that allows the agent to list available reports and run a selected report
    from the Auto Chlor System Web Portal.
    """"""

    name: Literal[""reports""] = ""reports""
    api_type: Literal[""custom""] = ""custom""
    description: str = ""A tool that allows the agent to list available reports and run a selected report from the Auto Chlor System Web Portal.""
    height: int
    display_num: Optional[int]

    _screenshot_delay = 1.0
    _scaling_enabled = True

    @property
    def options(self) -> Options:
        return {
            ""display_width_px"": self.width,
            ""display_height_px"": self.height,
            ""display_number"": self.display_num,
        }

    def to_params(self) -> dict:
        return {
            ""name"": self.name,
            ""description"": self.description,
            ""type"": self.api_type,
            ""input_schema"": {  # Use parameters instead of custom.input_schema
                ""type"": ""object"",
                ""properties"": {
                    ""command"": {
                        ""type"": ""string"",
                        ""enum"": [""list_reports"", ""run_report""],
                        ""description"": ""The command to execute. Either 'list_reports' to list all reports or 'run_report' to execute a specific report.""
                    },
                    ""report_name"": {
                        ""type"": ""string"",
                        ""description"": ""The name of the report to run. Required if command is 'run_report'.""
                    }
                },
                ""required"": [""command""],
            }
        }
        
    async def __call__(     
        self,
        *,
        command: Literal[""list_reports"", ""run_report""],
        report_name: Optional[str] = None,
        **kwargs,
    ) -> ToolResult:
        """"""
        Executes the specified command.
        """"""
        if command == ""list_reports"":
            return await self.list_reports()
        elif command == ""run_report"":
            if not report_name:
                raise ToolError(""Parameter `report_name` is required for command: run_report"")
            return await self.run_report(report_name)
        else:
            raise ToolError(
                f""Unrecognized command '{command}'. Allowed commands: 'list_reports', 'run_report'.""
            )

    async def list_reports(self) -> ToolResult:
        """"""
        Lists all available reports.
        """"""
        try:
            # Example: Replace with your actual data source
            df = pd.read_csv(r""C:\Users\Machine81\code\anthropic-quickstarts\computer-use-demo\computer_use_demo\filtered_links.csv"")  # Ensure this path is correct
            report_list = ""\n"".join(f""- {name}"" for name in df['display_name'])
            # ic(report_list)
            return ToolResult(output=f""Available Reports:\n{report_list}"")
        except Exception as e:
            raise ToolError(f""Failed to list reports: {str(e)}"")

    async def run_report(self, report_name: str) -> ToolResult:
        """"""
        Runs the specified report by finding the closest match and opening the URL.
        """"""
        try:
            # Example: Replace with your actual data source
            df = pd.read_csv(r""C:\Users\Machine81\code\anthropic-quickstarts\computer-use-demo\computer_use_demo\filtered_links.csv"")  # Ensure this path is correct
            ic(df.head())
            # replace _ with space in report_name
            report_name = report_name.replace(""_"", "" "")
            rr(report_name)
            matches = difflib.get_close_matches(report_name, df['display_name'], n=1, cutoff=0.1,)
            ic(matches)
            if not matches:
                raise ToolError(f""No matching report found for '{report_name}'."")

            best_match = matches[0]

            url_suffix = df.loc[df['display_name'] == best_match, 'url'].iloc[0]
            full_url = f""https://www.autochlor.net/wps/{url_suffix}""
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=False)
                context = await browser.new_context(storage_state=r""C:\mygit\compuse\computer_use_demo\state.json"")
                page = await context.new_page()
                await page.goto(full_url)
                # press the PRINT button
                page.click('input[type=""submit""][value=""PRINT""]')

            return ToolResult(output=""That report is available "")
        except Exception as e:
            raise ToolError(f""Failed to run report '{report_name}': {str(e)}"")
        


    async def download_file(self, url: str):

        # Initialize Playwright
        async with async_playwright() as p:
            # Launch Chromium with specified user data directory
            browser = await p.chromium.launch(channel=""chrome"", headless=False)
            context = browser.new_context(storage_state=r""C:\mygit\compuse\computer_use_demo\state.json"")
            # Navigate to page (state will be preserved)
            page.goto('https://www.autochlor.net/wps')
            
            # Verify state is loaded
            cookies = context.cookies()
            local_storage = page.evaluate(""""""() => {
                return Object.entries(localStorage);
            }"""""")
            
 
            # Open a new page
            page = await browser.new_page()

            await page.goto(url)

            # Directory to save downloads
            download_path = os.path.join(os.getcwd(), ""downloads"")
            os.makedirs(download_path, exist_ok=True)

            for index, row in df.iterrows():
                if row['url_type'] == 'File':
                    file_url = base_url + row['url']
                    rr(f""Downloading from URL: {file_url}"")

                    try:
                        # Listen for the download event
                        async with page.expect_download() as download_info:
                            await page.goto(file_url)
                        download = await download_info.value
                        
                        # Save the downloaded file to the specified path
                        await download.save_as(os.path.join(download_path, download.suggested_filename))
                        rr(f""Downloaded: {download.suggested_filename}"")

                    except Exception as e:
                        rr(f""Error downloading from URL: {file_url}"")
                        rr(e)

            # Close the browser after all downloads
            await browser.close()   "
c:\mygit\compuse\computer_use_demo\tools\playwright.py,"#playwright.py
import os
import logging
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from typing import Literal, Optional, Dict, Any, List
import requests
from bs4 import BeautifulSoup, Comment  # Add Comment to the import
import re
from .base import ToolResult
# Configure logging for user feedback and debugging
logging.basicConfig(level=logging.CRITICAL, format='%(asctime)s - %(levelname)s - %(message)s')

class WebNavigatorTool:
    """"""
    A versatile tool that uses Playwright to interact with the web, including reading information,
    navigating websites, filling forms, extracting data, interacting with dynamic elements, and downloading files.
    It also integrates with external APIs and includes enhanced error handling and #logging.
    """"""

    name: Literal[""web_navigator""] = ""web_navigator""
    api_type: Literal[""custom""] = ""custom""
    description: str = (
        ""A comprehensive tool that uses Playwright to perform various web interactions such as reading information, ""
        ""navigating websites, filling out forms, extracting data, interacting with dynamic elements, and downloading files. ""
        ""It also integrates with external APIs and includes enhanced error handling and logging for improved user experience.""
    )

    def __init__(self, download_dir: Optional[str] = None, api_credentials: Optional[Dict[str, Any]] = None):
        """"""
        Initializes the WebNavigatorTool with optional download directory and API credentials.
        """"""
        self.download_dir = download_dir or os.path.join(os.getcwd(), ""downloads"")
        os.makedirs(self.download_dir, exist_ok=True)
        self.api_credentials = api_credentials or {}
        self.session_history = []  # For contextual awareness
        logging.info(""WebNavigatorTool initialized with download directory at '%s'."", self.download_dir)


    def to_params(self) -> dict:
        """"""
        Defines the parameters for the tool, specifying the input schema.
        """"""
        return {
            ""name"": self.name,
            ""description"": self.description,
            ""type"": self.api_type,
            ""input_schema"": {
                ""type"": ""object"",
                ""properties"": {
                    ""url"": {
                        ""type"": ""string"",
                        ""description"": ""The URL to perform the action on.""
                    },
                    ""action"": {
                        ""type"": ""string"",
                        ""enum"": [""read"", ""navigate"", ""download"", ""fill_form"", ""extract_data"", ""click_element""],
                        ""description"": ""The action to perform.""
                    },
                    ""params"": {
                        ""type"": ""object"",
                        ""description"": ""Additional parameters required for the action."",
                        ""properties"": {
                            ""file_path"": {
                                ""type"": ""string"",
                                ""description"": ""Path to save the downloaded file (required for 'download' action).""
                            },
                            ""form_selector"": {
                                ""type"": ""string"",
                                ""description"": ""CSS selector for the form to fill (required for 'fill_form' action).""
                            },
                            ""form_data"": {
                                ""type"": ""object"",
                                ""additionalProperties"": {
                                    ""type"": ""string""
                                },
                                ""description"": ""Data to fill into the form fields.""
                            },
                            ""data_selector"": {
                                ""type"": ""string"",
                                ""description"": ""CSS selector for data extraction (required for 'extract_data' action).""
                            },
                            ""element_selector"": {
                                ""type"": ""string"",
                                ""description"": ""CSS selector of the element to click (required for 'click_element' action).""
                            }
                        }
                    }
                },
                ""required"": [""url"", ""action""]
            }
        }
    async def __call__(
        self,
        url: str,
        action: Literal[""read"", ""navigate"", ""download"", ""fill_form"", ""extract_data"", ""click_element""],
        params: Optional[Dict[str, Any]] = None
    ) -> ToolResult:  
        """"""        Args:
            url (str): The URL to perform the action on.
            action (Literal[""read"", ""navigate"", ""download"", ""fill_form"", ""extract_data"", ""click_element""]): 
                The action to perform. Must be one of ""read"", ""navigate"", ""download"", ""fill_form"", ""extract_data"", ""click_element"".
            params (Optional[Dict[str, Any]]): Optional parameters for the action. 
                - For ""download"", requires ""file_path"".
                - For ""fill_form"", requires ""form_selector"" and ""form_data"".
                - For ""extract_data"", requires ""data_selector"".
                - For ""click_element"", requires ""element_selector"".
        Returns:
            ToolResult: A ToolResult object containing the output or error message.
        Raises:
            ValueError: If required parameters for the specified action are missing.
            PlaywrightTimeoutError: If a timeout occurs while performing the action.
            Exception: For any other errors that occur during the action.
        Executes the specified action on the given URL with optional parameters.
        Returns a ToolResult object containing the output or error message.
        """"""
        params = params or {}
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)
            context = await browser.new_context(storage_state=r""C:\mygit\compuse\computer_use_demo\state.json"")
            page = await context.new_page()

            try:
                result = None
                if action == ""read"":
                    result = await self.read_info(page, url)
                elif action == ""navigate"":
                    result = await self.navigate_website(page, url)
                elif action == ""download"":
                    file_path = params.get(""file_path"")
                    if not file_path:
                        raise ValueError(""Parameter `file_path` is required for action: download"")
                    result = await self.download_file(page, url, file_path)
                elif action == ""fill_form"":
                    form_selector = params.get(""form_selector"")
                    form_data = params.get(""form_data"")
                    if not form_selector or not form_data:
                        raise ValueError(""Parameters `form_selector` and `form_data` are required for action: fill_form"")
                    result = await self.fill_form(page, url, form_selector, form_data)
                elif action == ""extract_data"":
                    data_selector = params.get(""data_selector"")
                    if not data_selector:
                        raise ValueError(""Parameter `data_selector` is required for action: extract_data"")
                    result = await self.extract_data(page, url, data_selector)
                elif action == ""click_element"":
                    element_selector = params.get(""element_selector"")
                    if not element_selector:
                        raise ValueError(""Parameter `element_selector` is required for action: click_element"")
                    result = await self.click_element(page, url, element_selector)
                else:
                    raise ValueError(f""Unrecognized action '{action}'"")
                
                return ToolResult(output=result)  # Return successful result

            except PlaywrightTimeoutError:
                error_msg = f""Timeout occurred while performing action '{action}' on {url}.""
                logging.error(error_msg)
                return ToolResult(error=error_msg)  # Return timeout error
            except Exception as e:
                error_msg = f""An error occurred while performing action '{action}' on {url}: {str(e)}""
                #logging.error(error_msg)
                return ToolResult(error=error_msg)  # Return general error
            # finally:
            #     await browser.close()

    async def read_info(
            self, 
            page, 
            url: str,
            content_type: str = ""structured"",  # Options: ""raw"", ""cleaned"", ""text"", ""structured""
            selectors: Optional[List[str]] = None,  # CSS selectors to specifically target
            exclude_selectors: Optional[List[str]] = None,  # CSS selectors to exclude
            remove_scripts: bool = True,
            remove_styles: bool = True,
            remove_comments: bool = True,
            preserve_links: bool = True,
            max_length: Optional[int] = None
        ) -> str:
            """"""
            Reads and processes the content of the specified URL.
            
            Args:
                page: Playwright page object
                url: Target URL
                content_type: Type of content processing to apply
                selectors: List of CSS selectors to specifically target
                exclude_selectors: List of CSS selectors to exclude
                remove_scripts: Whether to remove script tags
                remove_styles: Whether to remove style tags
                remove_comments: Whether to remove HTML comments
                preserve_links: Whether to preserve href attributes in the output
                max_length: Maximum length of returned content
            """"""
            await page.goto(url)
            raw_html = await page.content()
            self.session_history.append(f""read_info: {url}"")
            
            # Create BeautifulSoup object for parsing
            soup = BeautifulSoup(raw_html, 'html.parser')

            if content_type == ""raw"":
                return raw_html

            # Remove unwanted elements
            if remove_scripts:
                for script in soup.find_all('script'):
                    script.decompose()

            if remove_styles:
                for style in soup.find_all('style'):
                    style.decompose()
                # Remove inline styles
                for tag in soup.find_all(style=True):
                    del tag['style']

            if remove_comments:
                for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):
                    comment.extract()

            # Remove tracking and analytics elements
            tracking_classes = {'analytics', 'tracking', 'advertisement', 'ad-', 'cookie-banner'}
            for element in soup.find_all(class_=lambda x: x and any(track in x.lower() for track in tracking_classes)):
                element.decompose()

            # Process based on content type
            if content_type == ""cleaned"":
                # Keep only specified selectors if provided
                if selectors:
                    new_soup = BeautifulSoup('', 'html.parser')
                    for selector in selectors:
                        for element in soup.select(selector):
                            new_soup.append(element)
                    soup = new_soup

                # Remove excluded selectors
                if exclude_selectors:
                    for selector in exclude_selectors:
                        for element in soup.select(selector):
                            element.decompose()

                # Clean up remaining HTML
                for tag in soup.find_all(True):
                    # Remove empty tags
                    if len(tag.get_text(strip=True)) == 0 and tag.name not in ['img', 'br', 'hr']:
                        tag.decompose()
                        continue
                    
                    # Remove all attributes except href if preserve_links is True
                    if preserve_links and tag.name == 'a':
                        href = tag.get('href', '')
                        tag.attrs = {'href': href} if href else {}
                    else:
                        tag.attrs = {}

                content = str(soup)

            elif content_type == ""text"":
                # Extract only text content
                content = soup.get_text(separator=' ', strip=True)
                # Clean up whitespace
                content = re.sub(r'\s+', ' ', content)

            elif content_type == ""structured"":
                # Create a structured representation of the content
                content = self._create_structured_content(soup)

            else:
                raise ValueError(f""Unsupported content_type: {content_type}"")

            # Truncate if max_length is specified
            if max_length and len(content) > max_length:
                content = content[:max_length] + ""...""

            logging.info(""Read and processed content from '%s' using mode '%s'."", url, content_type)
            return content
    def _create_structured_content(self, soup: BeautifulSoup) -> str:
        """"""
        Creates a structured representation of the content.
        """"""
        structure = []
        
        # Extract title
        title = soup.title.string if soup.title else """"
        if title:
            structure.append(f""Title: {title.strip()}"")

        # Extract headings
        headings = []
        for tag in ['h1', 'h2', 'h3']:
            for heading in soup.find_all(tag):
                text = heading.get_text(strip=True)
                if text:
                    headings.append(f""{tag.upper()}: {text}"")
        if headings:
            structure.append(""\nHeadings:\n"" + ""\n"".join(headings))

        # Extract main content areas
        main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
        if main_content:
            content_text = main_content.get_text(separator=' ', strip=True)
            content_text = re.sub(r'\s+', ' ', content_text)
            structure.append(""\nMain Content:\n"" + content_text)

        # Extract links
        links = []
        for link in soup.find_all('a', href=True):
            text = link.get_text(strip=True)
            href = link['href']
            if text and href:
                links.append(f""- {text}: {href}"")
        if links:
            structure.append(""\nLinks:\n"" + ""\n"".join(links))

        return ""\n\n"".join(structure)
    async def navigate_website(self, page, url: str) -> str:
        """"""
        Navigates to the specified URL and returns the page title.
        """"""
        await page.goto(url)
        title = await page.title()
        self.session_history.append(f""navigate: {url}"")
        logging.info(""Navigated to '%s' with title '%s'."", url, title)
        return f""Navigated to {url}. Page title: {title}""

    async def download_file(self, page, url: str, file_path: str) -> str:
        """"""
        Downloads a file from the specified URL and saves it to the given file path.
        """"""
        os.makedirs(self.download_dir, exist_ok=True)
        async with page.expect_download() as download_info:
            await page.goto(url)
        download = await download_info.value
        save_path = os.path.join(self.download_dir, file_path)
        await download.save_as(save_path)
        self.session_history.append(f""download_file: {save_path}"")
        logging.info(""Downloaded file from '%s' to '%s'."", url, save_path)
        return f""File downloaded and saved to {save_path}""

    async def fill_form(self, page, url: str, form_selector: str, form_data: Dict[str, str]) -> str:
        """"""
        Fills out a form identified by form_selector with the provided form_data.
        """"""
        await page.goto(url)
        for field, value in form_data.items():
            await page.fill(f""{form_selector} {field}"", value)
        await page.click(f""{form_selector} button[type='submit']"")
        self.session_history.append(f""fill_form: {url} with {form_data}"")
        logging.info(""Filled form on '%s' with data '%s'."", url, form_data)
        return f""Form on {url} filled with provided data and submitted.""

    async def extract_data(self, page, url: str, data_selector: str) -> str:
        """"""
        Extracts and returns data from the specified selector on the webpage.
        """"""
        await page.goto(url)
        data = await page.inner_text(data_selector)
        self.session_history.append(f""extract_data: {url} - {data_selector}"")
        logging.info(""Extracted data from '%s' using selector '%s'."", url, data_selector)
        return data

    async def click_element(self, page, url: str, element_selector: str) -> str:
        """"""
        Clicks an element identified by the selector on the webpage.
        """"""
        await page.goto(url)
        await page.click(element_selector)
        self.session_history.append(f""click_element: {url} - {element_selector}"")
        logging.info(""Clicked element '%s' on '%s'."", element_selector, url)
        return f""Clicked element '{element_selector}' on {url}.""

    def integrate_external_api(self, api_url: str, params: Optional[Dict[str, Any]] = None) -> Any:
        """"""
        Integrates with an external API and returns the response.
        """"""
        params = params or {}
        headers = {
            ""Authorization"": f""Bearer {self.api_credentials.get('api_key', '')}"",
            ""Content-Type"": ""application/json""
        }
        response = requests.get(api_url, headers=headers, params=params)
        if response.status_code == 200:
            logging.info(""Successfully integrated with external API '%s'."", api_url)
            return response.json()
        else:
            logging.error(""Failed to integrate with external API '%s'. Status code: %s"", api_url, response.status_code)
            raise ConnectionError(f""Failed to connect to external API '{api_url}'. Status code: {response.status_code}"")

    def get_session_history(self) -> str:
        """"""
        Returns the session history for contextual awareness.
        """"""
        history = ""\n"".join(self.session_history)
        logging.info(""Session history retrieved."")
        return history
"
c:\mygit\compuse\computer_use_demo\tools\run.py,"## run.py
""""""Utility to run shell commands asynchronously with a timeout.""""""

import asyncio

TRUNCATED_MESSAGE: str = ""<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file the line numbers of what you are looking for. Remember to use you are working in Windows.</NOTE>""
MAX_RESPONSE_LEN: int = 16000


def maybe_truncate(content: str, truncate_after: int | None = MAX_RESPONSE_LEN):
    """"""Truncate content and append a notice if content exceeds the specified length.""""""
    return (
        content
        if not truncate_after or len(content) <= truncate_after
        else content[:truncate_after] + TRUNCATED_MESSAGE
    )


async def run(
    cmd: str,
    timeout: float | None = 120.0,  # seconds
    truncate_after: int | None = MAX_RESPONSE_LEN,
):
    """"""Run a shell command asynchronously with a timeout.""""""
    process = await asyncio.create_subprocess_shell(
        cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
    )

    try:
        stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=timeout)
        return (
            process.returncode or 0,
            maybe_truncate(stdout.decode(), truncate_after=truncate_after),
            maybe_truncate(stderr.decode(), truncate_after=truncate_after),
        )
    except asyncio.TimeoutError as exc:
        try:
            process.kill()
        except ProcessLookupError:
            pass
        raise TimeoutError(
            f""Command '{cmd}' timed out after {timeout} seconds""
        ) from exc
"
c:\mygit\compuse\computer_use_demo\tools\windows_navigation.py,"# tools/windows_navigation.py

import pyautogui
import time
from typing import Literal, Optional, Dict, Any
from pathlib import Path
import json
import logging
from .base import BaseAnthropicTool, ToolResult, ToolError
from rich import print as rr

# Configure logging
logging.basicConfig(level=logging.CRITICAL)
logger = logging.getLogger(__name__)

class WindowsNavigationTool:
    """"""
    A tool specializing in navigating Windows and Windows applications using keyboard shortcuts.
    """"""

    name: Literal[""windows_navigate""] = ""windows_navigate""
    api_type: Literal[""custom""] = ""custom""
    description: str = (
        ""A comprehensive tool for Windows navigation using keyboard shortcuts. ""
        ""Supports window management, file operations, system controls, and accessibility features. ""
        ""Uses pyautogui to simulate keyboard and mouse inputs for automated Windows control.""
    )

    def __init__(self):
        """"""Initialize the WindowsNavigationTool with shortcuts configuration.""""""
        self.shortcuts_file = Path(__file__).parent / ""windows_shortcuts.json""
        self.shortcuts = self._load_shortcuts()
        self.session_history = []  # Track navigation actions
        logging.info(""WindowsNavigationTool initialized with shortcuts from '%s'"", self.shortcuts_file)

    def _load_shortcuts(self) -> Dict[str, Any]:
        """"""Load keyboard shortcuts from JSON file.""""""
        try:
            if self.shortcuts_file.exists():
                with open(self.shortcuts_file, 'r') as f:
                    return json.load(f)
            else:
                logger.warning(f""Shortcuts file not found at {self.shortcuts_file}"")
                return {}
        except Exception as e:
            logger.error(f""Error loading shortcuts: {e}"")
            return {}

    def to_params(self) -> dict:
        """"""Define the parameters for the tool.""""""
        return {
            ""name"": self.name,
            ""description"": self.description,
            ""type"": self.api_type,
            ""input_schema"": {
                ""type"": ""object"",
                ""properties"": {
                    ""action"": {
                        ""type"": ""string"",
                        ""enum"": [
                            # Window Management
                            ""switch_window"", ""open_start_menu"", ""minimize_window"", 
                            ""maximize_window"", ""restore_window"", ""close_window"", 
                            ""take_screenshot"", ""go_to_desktop"",
                            ""switch_virtual_desktop_left"", ""switch_virtual_desktop_right"",
                            
                            # File Explorer
                            ""open_file_explorer"", ""refresh_explorer"",
                            
                            # Taskbar
                            ""open_task_manager"", ""lock_workstation"", ""sign_out"", 
                            ""hibernate"", ""sleep"",
                            
                            # Clipboard Operations
                            ""copy"", ""paste"", ""cut"", ""select_all"",
                            
                            # System Controls
                            ""open_run_dialog"", ""open_settings"", ""open_search"",
                            
                            # Accessibility
                            ""toggle_high_contrast"", ""toggle_narrator"", ""toggle_magnifier""
                        ],
                        ""description"": ""The Windows action to perform""
                    },
                    ""modifier"": {
                        ""type"": ""string"",
                        ""enum"": [""ctrl"", ""alt"", ""shift"", ""win""],
                        ""description"": ""Optional modifier key(s)""
                    },
                    ""target"": {
                        ""type"": ""string"",
                        ""description"": ""Optional target for the action (e.g., window title)""
                    }
                },
                ""required"": [""action""]
            }
        }

    async def __call__(
        self,
        action: str,
        modifier: Optional[str] = None,
        target: Optional[str] = None
    ) -> ToolResult:
        """"""
        Execute the requested Windows action.
        
        Args:
            action (str): The action to perform (must be one of the defined actions)
            modifier (Optional[str]): Optional modifier key(s)
            target (Optional[str]): Optional target for the action
            
        Returns:
            ToolResult: Contains either the success output or error message
        """"""
        try:
            # Get shortcut configuration
            shortcut = self.shortcuts.get(action)
            if not shortcut:
                return ToolResult(error=f""Unknown action: {action}"")

            # Prepare keys sequence
            keys = shortcut[""keys""]
            if modifier:
                keys = [modifier] + keys

            # Execute the shortcut
            result = await self._execute_action(action, keys, target)
            
            # Log the action
            self.session_history.append(f""{action}: {result.output if result.output else result.error}"")
            
            return result

        except Exception as e:
            error_msg = f""Error executing {action}: {str(e)}""
            logger.error(error_msg)
            return ToolResult(error=error_msg)

    async def _execute_action(self, action: str, keys: list, target: Optional[str] = None) -> ToolResult:
        """"""Execute a Windows action with the given keys and target.""""""
        try:
            # Activate window if needed
            if target and ""window"" in action.lower():
                windows = pyautogui.getWindowsWithTitle(target)
                if not windows:
                    return ToolResult(error=f""No window found with title '{target}'"")
                windows[0].activate()
                time.sleep(0.5)

            # Execute the key combination
            pyautogui.hotkey(*keys)
            time.sleep(0.1)  # Small delay for action to complete

            # Handle any follow-up input
            if target and self.shortcuts.get(action, {}).get(""requires_target"", False):
                pyautogui.typewrite(target)
                pyautogui.press('enter')

            success_msg = f""Successfully executed '{action}'""
            if target:
                success_msg += f"" with target '{target}'""
            
            logger.info(success_msg)
            return ToolResult(output=success_msg)

        except Exception as e:
            error_msg = f""Failed to execute {action}: {str(e)}""
            logger.error(error_msg)
            return ToolResult(error=error_msg)

    def get_session_history(self) -> str:
        """"""Returns the session history of navigation actions.""""""
        return ""\n"".join(self.session_history)"
c:\mygit\compuse\computer_use_demo\tools\__init__.py,"from .base import BaseAnthropicTool, ToolError, ToolResult
from .bash import BashTool
from .computer import ComputerTool
from .edit import EditTool
from .collection import ToolCollection
from .expert import GetExpertOpinionTool
from .playwright import WebNavigatorTool
from .gotourl_reports import GoToURLReportsTool
from .windows_navigation import WindowsNavigationTool

__all__ = [
    ""BaseAnthropicTool"",
    ""ToolError"",
    ""ToolResult"",
    ""BashTool"",
    ""ComputerTool"",
    ""EditTool"",
    ""ToolCollection"",
    ""GetExpertOpinionTool"",
    ""WebNavigatorTool"",
    ""GoToURLReportsTool"",
    ""WindowsNavigationTool""
]

"
